{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedbellaaj10/GPGPU_TP/blob/main/updated_linear_classification_2021_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ewR7_sHJ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca11ecf9-87e9-44f7-cc59-5a3b9e9edeaf"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download repository with helper_cuda.h:"
      ],
      "metadata": {
        "id": "neVqpQNceYFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ase9AQyweUSJ",
        "outputId": "358c9719-ff8e-481a-d4f4-7b2b28c33d18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 18274, done.\u001b[K\n",
            "remote: Counting objects: 100% (3689/3689), done.\u001b[K\n",
            "remote: Compressing objects: 100% (576/576), done.\u001b[K\n",
            "remote: Total 18274 (delta 3346), reused 3150 (delta 3113), pack-reused 14585\u001b[K\n",
            "Receiving objects: 100% (18274/18274), 133.19 MiB | 7.07 MiB/s, done.\n",
            "Resolving deltas: 100% (16006/16006), done.\n",
            "Updating files: 100% (3998/3998), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIyq5vPjxKc"
      },
      "source": [
        "Based on the lecture at https://sites.google.com/site/frehseg/teaching/ia307"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweMlOB0L4mG"
      },
      "source": [
        "# Provided Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lgwhE1N5_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74aa79b-9328-46ca-d488-b7a9b9282669"
      },
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        "\n",
        "//MACRO TO DEBUGG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "/** Error checking for use with CUDA Dynamic Parallelism */\n",
        "/*\n",
        "#define cdpErrchk(ans) { cdpAssert((ans), __FILE__, __LINE__); }\n",
        "__device__ void cdpAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      printf(\"GPU kernel assert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) assert(0);\n",
        "   }\n",
        "}\n",
        "*/\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivrxLaYOYPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e543ff82-eb94-4f8c-9f95-c83925cb22f2"
      },
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "## fmatrix Matrix Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A97U902HMog4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847f82e7-66bd-43f0-9410-2976f898f0dc"
      },
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include \"cuda_stuff.cuh\" // for IDX2C\n",
        "\n",
        "////////////////////////////////////////\n",
        "// basic data structure and access macro\n",
        "////////////////////////////////////////\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    int cols;\n",
        "    int rows;\n",
        "} fmatrix;\n",
        "\n",
        "/** Access element (i,j) of matrix M\n",
        " *\n",
        " *  Usage example:\n",
        " *  For computing A = B^T + C), loop over i and j with:\n",
        " *    getfm(A,i,j) = getfm(B,j,i) + getfm(C,i,j);\n",
        " **/\n",
        "#define getfm(M,i,j) (M.data[IDX2C(i,j,M.rows)])\n",
        "\n",
        "////////////////////////////////////////\n",
        "// utility functions\n",
        "////////////////////////////////////////\n",
        "/** Returns the number of elements in the matrix.\n",
        " *\n",
        " *  Useful for computing, e.g., the size\n",
        " *  of a 1D-vector that contains the same numbers.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_elements(fmatrix mat);\n",
        "\n",
        "/** Returns the memory occupied by the matrix elements in bytes\n",
        " *  (not including the variables in the struct mat).\n",
        " *\n",
        " *  Useful for allocating memory for the data.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_size(fmatrix mat);\n",
        "\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_assert(fmatrix mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Create, copy, destroy\n",
        "////////////////////////////////////////\n",
        "/** Allocate memory on host */\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols);\n",
        "\n",
        "/** Allocate memory on device */\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols);\n",
        "\n",
        "/** Create a matrix representing columns [a,b) of M.\n",
        " *  Note that the new matrix uses a pointer to the\n",
        " *  data of M. The data is not copied to a new location.\n",
        " *  If M is destroyed, this matrix is useless.\n",
        " */\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b);\n",
        "\n",
        "/** Copy data from matrix on device to host\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy data from matrix on host to device\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from device to host, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from host to device, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host);\n",
        "\n",
        "/** Free data memory on host.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "\n",
        "/** Free data memory on device.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Input and Output\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host.\n",
        " *  If nb<0, print all rows.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device.\n",
        " *  If nb<0, print all rows.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print a matrix to a csv file.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat);\n",
        "\n",
        "/** Read a matrix from a csv file.\n",
        " *\n",
        " *  This version creates the matrix on the host first.\n",
        " */\n",
        "fmatrix fmatrix_device_from_csv(const char* filename);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Useful\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Create a matrix with random values between -1 and 1\n",
        " *  on the device */\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols);\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGwZ36ifWQ-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2141c03-7828-4e83-9640-7120055d9c49"
      },
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "// for reading CSV files, we use some C++\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "\n",
        "int fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "int fmatrix_size(fmatrix mat) {\n",
        "//    fmatrix_assert(mat);\n",
        "     return fmatrix_elements(mat) * sizeof(float);\n",
        "}\n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat));\n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk(\n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat))\n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_device.data, mat_host.data,\n",
        "                   fmatrix_size(mat_host),\n",
        "                   cudaMemcpyHostToDevice\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,\n",
        "                   fmatrix_size(mat_device),\n",
        "                   cudaMemcpyDeviceToHost\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_device);\n",
        "    fmatrix mat_host = fmatrix_create_on_host(mat_device.rows, mat_device.cols);\n",
        "    fmatrix_data_to_host(mat_host,mat_device);\n",
        "    return mat_host;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix mat_device = fmatrix_create_on_device(mat_host.rows, mat_host.cols);\n",
        "    fmatrix_data_to_device(mat_host,mat_device);\n",
        "    return mat_device;\n",
        "}\n",
        "\n",
        "/** We could do it like this, but it would not set our pointer M.data to 0.\n",
        "... fmatrix_free_on_host(M)\n",
        "void fmatrix_free_on_host(fmatrix mat) {\n",
        "    fmatrix_assert(mat);\n",
        "  free(mat.data);\n",
        "  mat.data = 0;\n",
        "  mat.cols = 0;\n",
        "  mat.rows = 0;\n",
        "}\n",
        "*/\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b) {\n",
        "    fmatrix_assert(M);\n",
        "    fmatrix A = {\n",
        "        .data = &getfm(M,0,a),\n",
        "        .cols = b-a,\n",
        "        .rows = M.rows\n",
        "    };\n",
        "    fmatrix_assert(A);\n",
        "    return A;\n",
        "}\n",
        "\n",
        "\n",
        "__host__\n",
        "__device__\n",
        "void fmatrix_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "   fmatrix_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat) {\n",
        "  // Open file\n",
        "  FILE* fp = fopen(filename, \"w\");\n",
        "  // allocate copy\n",
        "  fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "  for (int i = 0 ; i < tmp.rows; i++){\n",
        "    for (int j = 0 ; j<tmp.cols; j++){\n",
        "      // Note: %.15g gives 15 significant digits (full double precision)\n",
        "      fprintf(fp,\"%.15g\", getfm(tmp,i,j));\n",
        "      if (j+1<tmp.cols) {\n",
        "        fprintf(fp,\",\");\n",
        "      }\n",
        "    }\n",
        "    fprintf(fp,\"\\n\");\n",
        "  }\n",
        "  fmatrix_free_on_host(&tmp);\n",
        "  // Close file\n",
        "  fclose(fp);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_create_random_on_device_kernel(fmatrix M) {\n",
        "    // choose a seed (here: the same each launch)\n",
        "    unsigned long seed = 0;\n",
        "    int sequence = 0;\n",
        "    // first, initialize the random numbers\n",
        "    curandState state;\n",
        "    curand_init(seed, sequence, 0, &state);\n",
        "    for (int i = 0; i < fmatrix_elements(M); ++i) {\n",
        "        // curand_uniform creates numbers between 0 and 1\n",
        "        M.data[i] = (curand_uniform(&state)-0.5)*2.0;\n",
        "    }\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols) {\n",
        "    // Create an uninitialized matrix on the device\n",
        "    fmatrix M = fmatrix_create_on_device(rows,cols);\n",
        "    // Call a kernel with a single thread to fill the values\n",
        "    fmatrix_create_random_on_device_kernel<<<1,1>>>(M);\n",
        "\n",
        "    return M;\n",
        "}\n",
        "\n",
        "/* Count the number of rows and columns in a csv files (without headers) */\n",
        "void count_elements_in_csv(const char* filename, int* rows, int* cols) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "\n",
        "  *rows = 0;\n",
        "  *cols = 0;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int tempcols = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "          ++tempcols;\n",
        "        }\n",
        "        if (tempcols > *cols) {\n",
        "           *cols = tempcols;\n",
        "        }\n",
        "        ++(*rows);\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "/** Read the data from a csv file into an fmatrix on the host.\n",
        " *  Careful: We assume that the matrix has the right dimensions!\n",
        " *  Use count_elements_in_csv(...) to get the dimensions if\n",
        " *  unknown.\n",
        " */\n",
        "void fmatrix_fill_from_csv(fmatrix h_M,const char* filename) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int col = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "\t\t\t\t\tgetfm(h_M,row,col) = strtod(value.c_str(), NULL);\n",
        "          ++col;\n",
        "\t\t\t\t}\n",
        "        ++row;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_device_from_csv(const char* filename) {\n",
        "  // first read the file to count the number of elements\n",
        "  int rows = 0;\n",
        "  int cols = 0;\n",
        "  count_elements_in_csv(filename,&rows,&cols);\n",
        "\n",
        "  // allocate the matrix on the host\n",
        "  fmatrix h_M = fmatrix_create_on_host(rows,cols);\n",
        "\n",
        "  // read the data into the host matrix\n",
        "  fmatrix_fill_from_csv(h_M,filename);\n",
        "\n",
        "  // copy the matrix to the device\n",
        "  fmatrix M = fmatrix_copy_to_device(h_M);\n",
        "\n",
        "  // destroy the host matrix\n",
        "  fmatrix_free_on_host(&h_M);\n",
        "\n",
        "  return M;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKLTK8ELOdN"
      },
      "source": [
        "## Data I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD7rmOBmWfsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb65c4d0-d23b-409c-f660-053ca8791e1b"
      },
      "source": [
        "%%writefile read_csv.cuh\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef read_csv_H\n",
        "#define read_csv_H\n",
        "\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol);\n",
        "\n",
        "#endif"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing read_csv.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeedFsZ_WQx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6f7e49-0f56-4b6c-b545-744c40a8d4f7"
      },
      "source": [
        "%%writefile read_csv.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"cuda_stuff.cuh\" // for matrix indexing\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for reading the dataset from a file\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Read a csv file with a given number of rows and columns */\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol) {\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  double ioTemp;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row_count = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "      // read the headers (and discard)\n",
        "\t\t\tgetline(infile, row_as_string, '\\n');\n",
        "      cout << \"headers: \" << row_as_string << \"!\" << std::endl;\n",
        "      for(int i = 0; i < nbrow; i++){\n",
        "  \t\t\tgetline(infile, row_as_string, '\\n');\n",
        "        // cout << \"read line \" << row_as_string << \"!\" << std::endl;\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "\t\t\t  for(int j = 0; j < nbcol; j++){\n",
        "          getline(line_stream, value, ',');\n",
        "\t\t\t\t\tioTemp = strtod(value.c_str(), NULL);\n",
        "          // cout << \"(\"<<i<<\",\"<<j<<\") = \"<< ioTemp << std::endl;\n",
        "\n",
        "\t\t\t\t\tdata_array[IDX2C(i,j,nbrow)] = ioTemp;\n",
        "\n",
        "\t\t\t\t}\n",
        "        ++row_count;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "    cout << \"Read \" << row_count << \" rows.\" << std::endl;\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing read_csv.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8ilQdYYroU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27beee05-3370-4b04-861e-8b60701ad3d3"
      },
      "source": [
        "%%writefile preprocess_data.cuh\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef preprocess_data_H\n",
        "#define preprocess_data_H\n",
        "\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels );\n",
        "\n",
        "#endif"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocess_data.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaeUdw_KYaCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d486cec9-f5ca-4184-8382-354151f7b219"
      },
      "source": [
        "%%writefile preprocess_data.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"preprocess_data.cuh\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   ld = number of rows\n",
        "   Example of use: a[IDX2C(0, 1, 50)] */\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for preprocessing the data set\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Split data into inputs and labels. Allocated memory for inputs and labels.\n",
        "   Since cuBLAS is column major, each input is in a column.\n",
        "   We also add 1.0 as first element to each input vector.\n",
        "*/\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels ) {\n",
        "    // The inputs are the first nbrows-1 columns.\n",
        "    // The labels are the last column (index nbrows-1), booleanized\n",
        "    // by the condition >= above_threshold\n",
        "    *input_array = (float *)malloc(nbrows * nb_inputs * sizeof(float));\n",
        "    *label_array = (float *)malloc(nbrows * nb_labels * sizeof(float));\n",
        "    //cout << &input_array << \" and \"<< &label_array << \" data \" << data_array << std::endl;\n",
        "    cout << \"Allocated memory for inputs: \" << nbrows << \" rows, \"<< nb_inputs << \" columns.\" << std::endl;\n",
        "    cout << \"Allocated memory for labels: \" << nbrows << \" rows, \"<< nb_labels << \" columns.\" << std::endl;\n",
        "\n",
        "    // Copy the data to X\n",
        "    for(int i = 0; i < nbrows; i++){\n",
        "      // Set the first element of each x to 1\n",
        "      (*input_array)[IDX2C(0,i,nb_inputs)] = 1.0;\n",
        "      // Copy the rest of x\n",
        "\t\t\tfor(int j = 1; j < nb_inputs; j++){\n",
        "\t\t\t\t(*input_array)[IDX2C(j,i,nb_inputs)] = data_array[IDX2C(i,j-1,nbrows)];\n",
        "\t\t\t}\n",
        "      float median_house_value = data_array[IDX2C(i,nbcols-1,nbrows)];\n",
        "      (*label_array)[IDX2C(0,i,nb_labels)] = 0.0;\n",
        "      (*label_array)[IDX2C(1,i,nb_labels)] = 0.0;\n",
        "      if (median_house_value >= above_threshold) {\n",
        "        (*label_array)[IDX2C(0,i,nb_labels)] = 1.0;\n",
        "      } else {\n",
        "        (*label_array)[IDX2C(1,i,nb_labels)] = 1.0;\n",
        "      }\n",
        "\t\t}\n",
        "\n",
        "    // Show some entries for double checking\n",
        "    cout << \"Inputs (first \"<<print_rows<<\"):\" << std::endl;\n",
        "\t  for(int j = 0; j < nb_inputs; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*input_array)[IDX2C(j,i,nb_inputs)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "    cout << \"Labels (first \"<<print_rows<<\"):\" << std::endl;\n",
        "    for(int j = 0; j < nb_labels; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*label_array)[IDX2C(j,i,nb_labels)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocess_data.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHy3EAid05oA"
      },
      "source": [],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code That You Write"
      ],
      "metadata": {
        "id": "rR-9WFucUWLC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWS3hlAecOc"
      },
      "source": [
        "## Classifier Math"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_tmB-xbZKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85644a07-59a3-4881-ad8b-2e8cf2d6ac38"
      },
      "source": [
        "%%writefile classifier_math.cuh\n",
        "#ifndef classifier_math_H\n",
        "#define classifier_math_H\n",
        "\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "/** Returns a random float between min and max (including). */\n",
        "float float_rand( float min, float max );\n",
        "\n",
        "/** Initialize W with Xavier's method,\n",
        " *  scaled by a. */\n",
        "void xavier_weight_init(float a, fmatrix W);\n",
        "\n",
        "/** Compute the softmax for each column of Z and store in P **/\n",
        "void softmax_col(fmatrix P,fmatrix Z);\n",
        "\n",
        "///////////////////////////////////\n",
        "// TO BE COMPLETED\n",
        "// ... add your matrix math here\n",
        "///////////////////////////////////\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "/* Compute A = B^T */\n",
        "void fmatrix_transpose(fmatrix Z, fmatrix Z_T);\n",
        "\n",
        "void fmatrix_add(fmatrix P,float a,fmatrix Y);\n",
        "\n",
        "void sigma_mu(fmatrix A, fmatrix mu, fmatrix sigma);\n",
        "\n",
        "void normalization(fmatrix A, fmatrix mu, fmatrix sigma);\n",
        "\n",
        "\n",
        "#endif"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing classifier_math.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgXwgv6Bbo-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a44457-df7d-4445-845c-8b0eaf087818"
      },
      "source": [
        "%%writefile classifier_math.cu\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Auxiliary function\n",
        "/////////////////////////////////////////////////////////\n",
        "// generate random numbers in interval [min,max]\n",
        "float float_rand( float min, float max )\n",
        "{\n",
        "    float scale = rand() / (float) RAND_MAX; /* [0, 1.0] */\n",
        "    return min + scale * ( max - min );      /* [min, max] */\n",
        "}\n",
        "\n",
        "void xavier_weight_init(float a, fmatrix W){\n",
        "    for (int j = 0; j < W.rows  ; ++j) {\n",
        "      for (int i = 0; i < W.cols  ; ++i) {\n",
        "          getfm(W,j,i) = a * (1.0/sqrt(W.cols+W.rows)) * float_rand(-1.0,1.0);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_transpose_kernel(fmatrix Z, fmatrix Z_T) {\n",
        "\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / Z.rows;\n",
        "    int i = idx % Z.rows;\n",
        "\n",
        "    getfm(Z_T,j,i) = getfm(Z,i,j);\n",
        "\n",
        "    //int j = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    //int i = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "    //if (j < Z.rows && i < Z.cols )\n",
        "    /*for(int i=0; i<Z.cols; i++){\n",
        "      for(int j=0; j<Z.rows; j++){\n",
        "          getfm(Z_T,j,i) = getfm(Z,i,j);\n",
        "      }\n",
        "    }*/\n",
        "}\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_add_kernel(fmatrix P,float a,fmatrix Y) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / P.rows;\n",
        "    int i = idx % P.rows;\n",
        "    if (i < P.rows && j < P.cols ){\n",
        "        getfm(P,i,j) += a*getfm(Y,i,j);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void fmatrix_transpose(fmatrix Z, fmatrix Z_T) {\n",
        "\n",
        "    assert(Z.rows == Z_T.cols);\n",
        "    assert(Z.cols == Z_T.rows);\n",
        "\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(Z);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "\n",
        "    fmatrix_transpose_kernel<<< blocksPerGrid, threadsPerBlock >>>(Z, Z_T); // 1 thread pour la transposition\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "\n",
        "  }\n",
        "\n",
        "\n",
        "\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__\n",
        "void softmax_col_kernel(float *Z, float *P, int nb_ColZ, int nb_LigneZ) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\n",
        "    float s=0;\n",
        "\n",
        "\n",
        "    if (col < nb_ColZ){\n",
        "        for (int k=0; k<nb_LigneZ; k++){\n",
        "            s+=exp(Z[col*nb_LigneZ+k]);\n",
        "        }\n",
        "        for (int k=0; k<nb_LigneZ; k++) {\n",
        "            P[col*nb_LigneZ + k]=exp(Z[col*nb_LigneZ+k])/s;\n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void softmax_col(fmatrix P,fmatrix Z) {\n",
        "    assert(P.cols==Z.cols);\n",
        "    assert(P.rows==Z.rows);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the softmax here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "    int blocksize = 100;\n",
        "    dim3 dimBlock (blocksize);\n",
        "    dim3 dimGrid(ceil( Z.cols / (float)blocksize));\n",
        "    softmax_col_kernel <<< dimGrid, dimBlock >>>(Z.data, P.data, Z.cols, Z.rows);\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_multiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.cols; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,i,k)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.rows);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.cols == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Multiplication de matrice avec transpos√©\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_tmultiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.rows; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,k,i)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.cols);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.rows == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////////////////////////////\n",
        "////////////////////////////////////////////////////////////////////////////////\n",
        "/** Compute P = P + a*Y */\n",
        "void fmatrix_add(fmatrix P,float a,fmatrix Y) {\n",
        "    fmatrix_assert(P);\n",
        "    fmatrix_assert(Y);\n",
        "    assert(P.rows == Y.rows);\n",
        "    assert(P.cols == Y.cols);\n",
        "    int threadsPerBlock = fmatrix_elements(P);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_add_kernel<<< blocksPerGrid, threadsPerBlock >>>(P,a,Y);\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__\n",
        "void sigma_mu_kernel(fmatrix X, fmatrix mu, fmatrix sigma ) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / X.rows;\n",
        "    int i = idx % X.rows;\n",
        "    if (i < X.rows && j < X.cols ){\n",
        "      getfm(mu,i,0) = 0;\n",
        "      for (int k=0; k<X.cols; k++){\n",
        "          getfm(mu,i,0) += getfm(X,i,k);\n",
        "      }\n",
        "      getfm(mu,i,0) = getfm(mu,i,0) / (float) X.cols;\n",
        "\n",
        "      getfm(sigma,i,0) = 0;\n",
        "      for (int k=0; k<X.cols; k++){\n",
        "          getfm(sigma,i,0) += powf((getfm(X,i,k) - getfm(mu,i,0)), 2.0);\n",
        "      }\n",
        "      getfm(sigma,i,0) =  sqrtf(getfm(sigma,i,0) / (float) X.cols);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void normalization_kernel(fmatrix X, fmatrix mu, fmatrix sigma) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / X.rows;\n",
        "    int i = idx % X.rows;\n",
        "\n",
        "    if (i < X.rows && j < X.cols ){\n",
        "      if (getfm(sigma,i,0) != 0){\n",
        "      getfm(X,i,j) = (getfm(X,i,j) - getfm(mu,i,0))/getfm(sigma,i,0) ;\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute sigma mu (A) */\n",
        "void sigma_mu(fmatrix A, fmatrix mu, fmatrix sigma) {\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    sigma_mu_kernel<<< blocksPerGrid, threadsPerBlock >>>(A, mu, sigma);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "/* Compute normalization(A) */\n",
        "void normalization(fmatrix A, fmatrix mu, fmatrix sigma) {\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    normalization_kernel<<< blocksPerGrid, threadsPerBlock >>>(A, mu, sigma);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing classifier_math.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6G22rDKR3rv"
      },
      "source": [
        "## Evaluating Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7Vmzo72hpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11949930-cfab-4b02-e590-99be1232b9a9"
      },
      "source": [
        "%%writefile evaluate_accuracy.cuh\n",
        "\n",
        "/** Evaluate the accuracy of a linear classifier with D x M weight\n",
        " *  matrix W, using D x N input data X and M x N output labels Y.\n",
        " *  Z is a temporary matrix with dimensions M x N,\n",
        " *  which must be previously allocated.\n",
        " */\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z);\n",
        "\n",
        "/** Compute the logloss given M x N matrices of\n",
        " *  probabilities P and output labels Y\n",
        " *  and stores it in J.\n",
        " *  J is a matrix with dimensions 1 x 1,\n",
        " *  which must be previously allocated.\n",
        " *  logloss = sum_j -Y(j,k)*log(P(j,k))\n",
        " */\n",
        "void evaluate_logloss(fmatrix d_P,fmatrix d_Y,fmatrix d_J);"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate_accuracy.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Z-9B4a2dwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f35f494e-d1de-4689-a0e9-a7e04d17875b"
      },
      "source": [
        "%%writefile evaluate_accuracy.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__\n",
        "void evaluate_accuracy_kernel(fmatrix d_Y,fmatrix d_Z,int* count) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    if (idx < d_Z.cols){\n",
        "        float z_max = getfm(d_Z,0,idx);\n",
        "        int i_max = 0;\n",
        "        for (int i = 1; i < d_Z.rows; ++i) {\n",
        "          if (getfm(d_Z,i,idx)>z_max) {\n",
        "                z_max = getfm(d_Z,i,idx);\n",
        "                i_max = i;\n",
        "          }\n",
        "        }\n",
        "      if (getfm(d_Y,i_max,idx)>=0.5f) {\n",
        "          atomicAdd(count,1);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z) {\n",
        "    assert(d_Y.cols == d_Z.cols);\n",
        "    assert(d_Y.rows == d_Z.rows);\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 1. compute Z = W^T X\n",
        "  // --> each column of Z corresponds to one input\n",
        "  //////////////////////////////////////////\n",
        "  fmatrix_tmult(d_Z, 1.0, d_W, d_X);\n",
        "\n",
        "  /*********************************\n",
        "  / TO BE COMPLETED\n",
        "  / ... compute Z = W^T X here ...\n",
        "  **********************************/\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 2. For each column z of Z,\n",
        "  // find argmax_k z_k\n",
        "  //////////////////////////////////////////\n",
        "\n",
        "  int true_class = 0;\n",
        "\n",
        "  int* d_count = 0;\n",
        "  gpuErrchk(cudaMalloc((void **)&d_count, sizeof(int)));\n",
        "  gpuErrchk(\n",
        "        cudaMemcpy( d_count, &true_class, sizeof(int), cudaMemcpyHostToDevice )\n",
        "  );\n",
        "\n",
        "    int threadsPerBlock = d_Z.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    evaluate_accuracy_kernel<<< blocksPerGrid, threadsPerBlock >>>(d_Y,d_Z,d_count);\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "  gpuErrchk(\n",
        "          cudaMemcpy(&true_class, d_count, sizeof(int), cudaMemcpyDeviceToHost )\n",
        "  );\n",
        "\n",
        "  //printf(\"Correct results: %d out of %d\\n\",true_class,nb_tested);\n",
        "  //printf(\"Accuracy: %f\\n\",(float)true_class/(float)nb_tested);\n",
        "  return (float)true_class/(float)d_Z.cols;\n",
        "}\n",
        "\n",
        "\n",
        "__global__\n",
        "void evaluate_logloss_kernel(fmatrix d_P,fmatrix d_Y, fmatrix d_J) {\n",
        "\n",
        "    getfm(d_J,0,0) = 0.0;\n",
        "    float temp = 0.0;\n",
        "    for(int k=0; k<d_Y.cols ; k++)\n",
        "      {\n",
        "        for(int j=0; j<d_Y.rows; j++){\n",
        "          if(getfm(d_Y,j,k) > 0.0 && getfm(d_P,j,k) > 0.0){\n",
        "            temp = -getfm(d_Y,j,k)*logf(getfm(d_P,j,k));\n",
        "            getfm(d_J,0,0) += temp;\n",
        "          }\n",
        "\n",
        "\n",
        "      }\n",
        "    }\n",
        "\n",
        "    getfm(d_J,0,0) *= 1.0 / d_Y.cols;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void evaluate_logloss(fmatrix d_P,fmatrix d_Y,fmatrix d_J) {\n",
        "    assert(d_Y.cols == d_P.cols);\n",
        "    assert(d_Y.rows == d_P.rows);\n",
        "    fmatrix_assert(d_Y);\n",
        "    fmatrix_assert(d_P);\n",
        "\n",
        "\n",
        "    //float J = 0.0;\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the logloss here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "    evaluate_logloss_kernel<<< 1, 1 >>>(d_P, d_Y, d_J);\n",
        "\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "    //return J;\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate_accuracy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!shuf sample_data/california_housing_train.csv > california_housing_train_shuff.csv"
      ],
      "metadata": {
        "id": "UY2VxLizKMRs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AwZh8WULi_F"
      },
      "source": [
        "## Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWO5p1NeHE9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba037793-d6b3-4968-ad15-22100f0d818b"
      },
      "source": [
        "%%writefile linear_classification.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"preprocess_data.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"evaluate_accuracy.cuh\"\n",
        "/* Includes, cuda */\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "/////////////////////////////////////////////////////////\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    size_t N_train = 12000; // 4; //12000; // points for training (Google: 12000)\n",
        "    size_t N_test = 5000; // 2; // 5000; // points for validation (Google: 5000)\n",
        "    size_t N = N_train;\n",
        "    size_t Nall = N_train+N_test;\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Reading the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    fmatrix alldata = fmatrix_create_on_host(Nall,data_columns);\n",
        "    read_csv(\"california_housing_train_shuff.csv\",alldata.data,Nall,data_columns);\n",
        "    //fmatrix_print(alldata);\n",
        "\n",
        "    size_t D = data_columns-1+1; // remove output column, add column with const. 1.0\n",
        "    size_t M = 2; // number of labels (one-hot encoding)\n",
        "    fmatrix Xall = fmatrix_create_on_host(D,Nall);\n",
        "    fmatrix Yall = fmatrix_create_on_host(M,Nall);\n",
        "    get_inputs_and_labels(alldata.data,&Xall.data,&Yall.data,Nall,data_columns,D,M);\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Inputs and labels are now available in X and Y.\n",
        "    // Each input is a column in X; X is of dimension D x N\n",
        "    // each label is a column in Y; Y is of dimension M x N\n",
        "    /////////////////////////////////////////////////////////\n",
        "\n",
        "    // Logfile\n",
        "    FILE* fp = fopen(\"log.txt\", \"w\");\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for Stochastic Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    int nb_iter = 30;           // defeault: 10;\n",
        "    int periods = nb_iter;      // reporting period\n",
        "    int batch_size = N;         // defeault: N;\n",
        "    float learning_rate = 1e-5; // default: 1e-7\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Memory Allocation and Initialization\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // take X,Y to be the first N columns of all data\n",
        "    fmatrix h_X = fmatrix_subcolumns(Xall,0,N);\n",
        "    fmatrix h_Y = fmatrix_subcolumns(Yall,0,N);\n",
        "    fmatrix h_Xtest = fmatrix_subcolumns(Xall,N,Nall);\n",
        "    fmatrix h_Ytest = fmatrix_subcolumns(Yall,N,Nall);\n",
        "    fmatrix h_W = fmatrix_create_on_host(D,M);\n",
        "    fmatrix h_J = fmatrix_create_on_host(1,1);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Initializing Weight Matrix\n",
        "    // its dimension is D x M\n",
        "    /////////////////////////////////////////////////////////\n",
        "    xavier_weight_init(1.0,h_W);\n",
        "\n",
        "    //////////////////////////////\n",
        "    // Copy data to device      //\n",
        "    //////////////////////////////\n",
        "    fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "    fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "    fmatrix d_Xtest = fmatrix_copy_to_device(h_Xtest);\n",
        "    fmatrix d_Ytest = fmatrix_copy_to_device(h_Ytest);\n",
        "    fmatrix d_W = fmatrix_copy_to_device(h_W);\n",
        "    fmatrix d_J = fmatrix_copy_to_device(h_J);\n",
        "\n",
        "    /////////////////////////////////////////\n",
        "    // Create auxiliary matrices on device //\n",
        "    /////////////////////////////////////////\n",
        "    fmatrix d_Z = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_P = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_G = fmatrix_create_on_device(D,M);\n",
        "    // auxiliary matrix for computing Z=W^T X on test data\n",
        "    fmatrix d_Ztest = fmatrix_create_on_device(M,d_Xtest.cols);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Batch Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    //fmatrix_device_print(d_X);\n",
        "    //fmatrix_device_print(d_W);\n",
        "\n",
        "    fmatrix mu = fmatrix_create_on_device(d_X.rows,1);\n",
        "    fmatrix sigma = fmatrix_create_on_device(d_X.rows,1);\n",
        "    sigma_mu(d_X, mu, sigma);\n",
        "    normalization(d_X, mu, sigma);\n",
        "\n",
        "    fmatrix mu_test = fmatrix_create_on_device(d_X.rows,1);\n",
        "    fmatrix sigma_test = fmatrix_create_on_device(d_X.rows,1);\n",
        "    sigma_mu(d_Xtest, mu_test, sigma_test);\n",
        "    normalization(d_Xtest, mu_test, sigma_test);\n",
        "\n",
        "     /* Evaluate the accuracy */\n",
        "    float accuracy = 0;\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"initial accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    float J = 0;\n",
        "\n",
        "    clock_t tstart_total, tend;\n",
        "    tstart_total = clock();\n",
        "\n",
        "    int batch_pointer = 0;\n",
        "    for (int i = 0; i < nb_iter; ++i )  {\n",
        "\n",
        "        //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "        //printf(\"X:\\n\");fmatrix_device_print(d_X);\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // compute Z = W^T X\n",
        "      // --> each column z of Z corresponds to one column x of X\n",
        "\n",
        "      ////////////////////////////////\n",
        "\n",
        "\n",
        "      ///////////////////////////////////\n",
        "      fmatrix h_X=fmatrix_subcolumns(Xall,batch_pointer, batch_pointer+batch_size);\n",
        "      fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "      fmatrix h_Y = fmatrix_subcolumns(Yall,batch_pointer,  batch_pointer+batch_size);\n",
        "      fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "\n",
        "      fmatrix_tmult(d_Z, 1.0, d_W, d_X);\n",
        "\n",
        "\n",
        "      ///////////////////////////////////\n",
        "\n",
        "\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // For each column z of Z, compute activation p(z);\n",
        "      // then update W\n",
        "      ////////////////////////////////\n",
        "\n",
        "      // compute softmax per column of Z and store in Z\n",
        "\n",
        "    ///////////////////////////////////\n",
        "        softmax_col(d_P, d_Z);\n",
        "        //printf(\"Z:\\n\"); fmatrix_device_print(d_Z);\n",
        "        //printf(\"P:\\n\"); fmatrix_device_print(d_P);\n",
        "        fmatrix h_P = fmatrix_copy_to_host(d_P);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "\n",
        "      // evaluate logloss (for reporting only)\n",
        "\n",
        "      evaluate_logloss(d_P, d_Y, d_J);\n",
        "      fmatrix_data_to_host(h_J,d_J);\n",
        "      J = getfm(h_J,0,0);\n",
        "\n",
        "      // Q:=P-Y\n",
        "      // compute gradient G = 1/batch_size XQ^T\n",
        "      // ... possibly work with G here ...\n",
        "      // update weights W = W - learning_rate*G\n",
        "\n",
        "                ///////////////////////////////////\n",
        "                // TO BE COMPLETED\n",
        "                ///////////////////////////////////\n",
        "\n",
        "                fmatrix h_Q = fmatrix_create_on_host(M,batch_size);\n",
        "                fmatrix d_Q = fmatrix_create_on_device(M,batch_size);\n",
        "                fmatrix d_Q_T = fmatrix_create_on_device(batch_size,M);\n",
        "\n",
        "                for(int l=0; l<M; l++){\n",
        "                  for(int j=0; j<batch_size; j++){\n",
        "                    getfm(h_Q,l,j) = 0.0;\n",
        "                  }\n",
        "                }\n",
        "\n",
        "                fmatrix_data_to_device(h_Q, d_Q);\n",
        "\n",
        "                fmatrix_add(d_Q, 1.0, d_P);\n",
        "                fmatrix_add(d_Q, -1.0, d_Y);\n",
        "\n",
        "                fmatrix_transpose(d_Q, d_Q_T);\n",
        "                fmatrix_mult(d_G, 1.0, d_X, d_Q_T);\n",
        "\n",
        "                //fmatrix_device_print(d_G);\n",
        "\n",
        "                fmatrix_add(d_W, -learning_rate, d_G);\n",
        "\n",
        "                //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "\n",
        "\n",
        "      // For reporting, compute logloss and accuracy\n",
        "      if (i%(nb_iter/periods)==0) {\n",
        "          float accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "          printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
        "          fprintf(fp, \"%f,%f\\n\", J, accuracy);\n",
        "          fflush(fp);\n",
        "        }\n",
        "\n",
        "\n",
        " }\n",
        "    tend = clock();\n",
        "    float duration = ((float)(tend-tstart_total))/CLOCKS_PER_SEC;\n",
        "    printf(\"Duration (s): %f\\n\",duration);\n",
        "    /* Evaluate the accuracy */\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"final accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    printf(\"final weights: \\n\");\n",
        "    fmatrix_device_print(d_W);\n",
        "\n",
        "    /* Memory clean up */\n",
        "    /** No need to free h_X, h_Y, h_Xtest, h_Ytest since\n",
        "     *  they all point to Xall\n",
        "     */\n",
        "    fmatrix_free_on_host(&h_W);\n",
        "    fmatrix_free_on_host(&Xall);\n",
        "    fmatrix_free_on_host(&Yall);\n",
        "\n",
        "    fmatrix_free_on_device(&d_X);\n",
        "    fmatrix_free_on_device(&d_Y);\n",
        "    fmatrix_free_on_device(&d_Xtest);\n",
        "    fmatrix_free_on_device(&d_Ytest);\n",
        "    fmatrix_free_on_device(&d_W);\n",
        "    fmatrix_free_on_device(&d_Z);\n",
        "    fmatrix_free_on_device(&d_J);\n",
        "\n",
        "    // Close log file\n",
        "    fclose(fp);\n",
        "}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting linear_classification.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrATC8s9LsDw"
      },
      "source": [
        "# Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z52xd0NMRKXb"
      },
      "source": [
        "!nvcc -Wno-deprecated-gpu-targets -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZVqTfXcLvPr"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GcUSYjJ1EEx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV_vFkIT7fV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd62674-8212-446e-b72c-aca0829c1da8"
      },
      "source": [
        "%%time\n",
        "!./a.out"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "headers: -117.080000,32.690000,36.000000,1571.000000,284.000000,1001.000000,268.000000,3.687500,111400.000000!\n",
            "Read 17000 rows.\n",
            "Allocated memory for inputs: 17000 rows, 9 columns.\n",
            "Allocated memory for labels: 17000 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "-117.66\t-117.65\t-122.41\t-118.43\t-118.13\t-116.99\t-118.22\t-118.43\t-121.07\t-121.37\t\n",
            "33.61\t33.59\t37.7\t34.16\t34.09\t32.83\t34.13\t33.96\t39.23\t38.68\t\n",
            "21\t8\t23\t41\t42\t20\t35\t38\t39\t35\t\n",
            "1932\t2649\t1817\t2050\t2562\t6696\t2983\t1104\t2099\t1620\t\n",
            "266\t340\t400\t478\t781\t1326\t526\t216\t433\t276\t\n",
            "860\t1238\t1376\t850\t1936\t3687\t1614\t415\t929\t939\t\n",
            "286\t354\t382\t490\t687\t1291\t543\t163\t423\t277\t\n",
            "7.1497\t8.0409\t2.4113\t3.4208\t2.2214\t3.1979\t5.7794\t6.1985\t1.9886\t2.5542\t\n",
            "Labels (first 10):\n",
            "1\t1\t0\t1\t0\t0\t1\t1\t0\t0\t\n",
            "0\t0\t1\t0\t1\t1\t0\t0\t1\t1\t\n",
            "initial accuracy: 0.519400\n",
            "iter: 0, logloss: 21.851824, accuracy: 0.730400\n",
            "iter: 1, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 2, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 3, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 4, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 5, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 6, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 7, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 8, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 9, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 10, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 11, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 12, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 13, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 14, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 15, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 16, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 17, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 18, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 19, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 20, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 21, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 22, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 23, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 24, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 25, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 26, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 27, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 28, logloss: 0.000000, accuracy: 0.250800\n",
            "iter: 29, logloss: 0.000000, accuracy: 0.250800\n",
            "Duration (s): 0.258106\n",
            "final accuracy: 0.250800\n",
            "final weights: \n",
            "[\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan\n",
            "]\n",
            "CPU times: user 11.8 ms, sys: 1.01 ms, total: 12.8 ms\n",
            "Wall time: 611 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIyxh0ClrIz"
      },
      "source": [
        "Let's plot the logloss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR2kCNEIlpqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "87ce2189-863e-4be2-b5ef-755a341e2af1"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('log.txt',sep=',',header=None)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data[0],label=\"logloss\")\n",
        "ax2=ax.twinx()\n",
        "ax2.plot([], [])\n",
        "ax2.plot(data[1],label=\"accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aUKkNJqTDZ"
      },
      "source": [
        "# Debugging\n",
        "Compile with debugging info on the host (`-g`) and device (`-G`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dtB5QKcWQ5M2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcfLGo1UrMq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241cd71d-97e6-41be-fd9f-51838620a247"
      },
      "source": [
        "!nvcc -g -G -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(76)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"learning_rate\"\u001b[0m was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(130)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"batch_pointer\"\u001b[0m was declared but never referenced\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuaGO10rRm9"
      },
      "source": [
        "Run the debugger cuda-gdb, stopping at the first error that is detected. Shows first the call stack on the GPU, the values of local variables, then the call stack on the host (thread 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ8nAtzGTRgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7caff4da-8a5b-40ce-ffe8-944dc41c7afb"
      },
      "source": [
        "! printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "! cat tmp.txt\n",
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set cuda memcheck on\n",
            "set cuda api_failures stop\n",
            "catch throw\n",
            "r\n",
            "bt\n",
            "info locals\n",
            "thread 1\n",
            "bt\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[New Thread 0x7fad67250000 (LWP 6223)]\n",
            "[Detaching after fork from child process 6224]\n",
            "[New Thread 0x7fad66723000 (LWP 6233)]\n",
            "[New Thread 0x7fad65f22000 (LWP 6234)]\n",
            "original matrix:\n",
            "[\n",
            "0.480439;\n",
            "-0.123098\n",
            "]\n",
            "[\n",
            "0.480439\n",
            "]\n",
            "a.out: classifier_math.cu:111: void fmatrix_tmult(fmatrix, float, fmatrix, fmatrix): Assertion `A.rows == B.cols' failed.\n",
            "\n",
            "Thread 1 \"a.out\" received signal SIGABRT, Aborted.\n",
            "0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#1  0x00007fad69a17859 in abort () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#2  0x00007fad69a17729 in ?? () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#3  0x00007fad69a28fd6 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#4  0x00005652aac0a584 in fmatrix_tmult (A=..., f=1, B=..., C=...) at classifier_math.cu:111\n",
            "#5  0x00005652aac0a7c7 in main () at test.cu:13\n",
            "No symbol table info available.\n",
            "[Switching to thread 1 (Thread 0x7fad699f2000 (LWP 6218))]\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#1  0x00007fad69a17859 in abort () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#2  0x00007fad69a17729 in ?? () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#3  0x00007fad69a28fd6 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#4  0x00005652aac0a584 in fmatrix_tmult (A=..., f=1, B=..., C=...) at classifier_math.cu:111\n",
            "#5  0x00005652aac0a7c7 in main () at test.cu:13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGJ6uVNBVHUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d044452-1f0e-4e79-9173-a176dc01a260"
      },
      "source": [
        "!cuda-memcheck ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= CUDA-MEMCHECK\n",
            "========= This tool is deprecated and will be removed in a future release of the CUDA toolkit\n",
            "========= Please use the compute-sanitizer tool as a drop-in replacement\n",
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 6 rows.\n",
            "Allocated memory for inputs: 6 rows, 9 columns.\n",
            "Allocated memory for labels: 6 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t\n",
            "15\t19\t17\t14\t20\t29\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t\n",
            "1283\t1901\t174\t337\t326\t236\t\n",
            "1015\t1129\t333\t515\t624\t671\t\n",
            "472\t463\t117\t226\t262\t239\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.000000\n",
            "iter: 0, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 1, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 2, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 3, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 4, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 5, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 6, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 7, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 8, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 9, logloss: 0.000000, accuracy: 0.000000\n",
            "Duration (s): 0.000850\n",
            "final accuracy: 0.000000\n",
            "final weights: \n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Pk-JL7rAhi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "6WEXHyvpQ-1O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqs64V1tEysf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736ead32-b8ff-4854-af18-99ea989f6ac8"
      },
      "source": [
        "%%writefile test.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cu\"\n",
        "\n",
        "int main() {\n",
        "    // create a random matrix\n",
        "    fmatrix A = fmatrix_create_random_on_device(2,1);\n",
        "    fmatrix B = fmatrix_create_random_on_device(1,2);\n",
        "    fmatrix C = fmatrix_create_random_on_device(1,1);\n",
        "    printf(\"original matrix:\\n\");\n",
        "    fmatrix_device_print(B);\n",
        "    fmatrix_device_print(C);\n",
        "    // add the matrix to itself\n",
        "    fmatrix_tmult(A,1.0,B,C);\n",
        "    // print\n",
        "    printf(\"matrix result:\\n\");\n",
        "    fmatrix_device_print(A);\n",
        "    // free the memory\n",
        "    fmatrix_free_on_device(&A);\n",
        "    fmatrix_free_on_device(&B);\n",
        "    fmatrix_free_on_device(&C);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Wno-deprecated-gpu-targets -g -G -I cuda-samples/Common/ -L/usr/local/cuda/include test.cu fmatrix.cu cuda_stuff.cu"
      ],
      "metadata": {
        "id": "KsKCSpp4PoKI",
        "outputId": "87d6d031-4e1f-463b-b2c0-39a835d43d8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/ld: /tmp/tmpxft_00002135_00000000-19_test.o: in function `mat_transp_mul(float, fmatrix, fmatrix, float, fmatrix, int)':\n",
            "/content/classifier_math.cu:65: undefined reference to `cublasCreate_v2'\n",
            "/usr/bin/ld: /content/classifier_math.cu:73: undefined reference to `cublasSgemm_v2'\n",
            "/usr/bin/ld: /content/classifier_math.cu:76: undefined reference to `cublasSgemm_v2'\n",
            "/usr/bin/ld: /content/classifier_math.cu:79: undefined reference to `cublasDestroy_v2'\n",
            "collect2: error: ld returned 1 exit status\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vErDd-FXQHdO",
        "outputId": "830d24f6-7093-4ab8-9080-aa0ea20bb518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./a.out: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uEbwlO9YJjH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}