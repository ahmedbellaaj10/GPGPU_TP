{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedbellaaj10/GPGPU_TP/blob/main/linear_classification_2021_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ewR7_sHJ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb630e9-24f9-4b5b-957e-bc8bec9df961"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download repository with helper_cuda.h:"
      ],
      "metadata": {
        "id": "neVqpQNceYFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ase9AQyweUSJ",
        "outputId": "c70da551-c050-48b4-9af6-16f4b9f20817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cuda-samples' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIyq5vPjxKc"
      },
      "source": [
        "Based on the lecture at https://sites.google.com/site/frehseg/teaching/ia307"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweMlOB0L4mG"
      },
      "source": [
        "# Provided Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lgwhE1N5_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a428f3e-1a64-45d6-dcd2-47ff7f2d0a16"
      },
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        "\n",
        "//MACRO TO DEBUGG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "/** Error checking for use with CUDA Dynamic Parallelism */\n",
        "/*\n",
        "#define cdpErrchk(ans) { cdpAssert((ans), __FILE__, __LINE__); }\n",
        "__device__ void cdpAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      printf(\"GPU kernel assert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) assert(0);\n",
        "   }\n",
        "}\n",
        "*/\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivrxLaYOYPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59caf952-0a33-4ce3-c0f5-bea3ec23e1aa"
      },
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_stuff.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "## fmatrix Matrix Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A97U902HMog4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f73af4d-10ea-4dae-cd54-08d032a3eaf0"
      },
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include \"cuda_stuff.cuh\" // for IDX2C\n",
        "\n",
        "////////////////////////////////////////\n",
        "// basic data structure and access macro\n",
        "////////////////////////////////////////\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    int cols;\n",
        "    int rows;\n",
        "} fmatrix;\n",
        "\n",
        "/** Access element (i,j) of matrix M\n",
        " *\n",
        " *  Usage example:\n",
        " *  For computing A = B^T + C), loop over i and j with:\n",
        " *    getfm(A,i,j) = getfm(B,j,i) + getfm(C,i,j);\n",
        " **/\n",
        "#define getfm(M,i,j) (M.data[IDX2C(i,j,M.rows)])\n",
        "\n",
        "////////////////////////////////////////\n",
        "// utility functions\n",
        "////////////////////////////////////////\n",
        "/** Returns the number of elements in the matrix.\n",
        " *\n",
        " *  Useful for computing, e.g., the size\n",
        " *  of a 1D-vector that contains the same numbers.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_elements(fmatrix mat);\n",
        "\n",
        "/** Returns the memory occupied by the matrix elements in bytes\n",
        " *  (not including the variables in the struct mat).\n",
        " *\n",
        " *  Useful for allocating memory for the data.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_size(fmatrix mat);\n",
        "\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_assert(fmatrix mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Create, copy, destroy\n",
        "////////////////////////////////////////\n",
        "/** Allocate memory on host */\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols);\n",
        "\n",
        "/** Allocate memory on device */\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols);\n",
        "\n",
        "/** Create a matrix representing columns [a,b) of M.\n",
        " *  Note that the new matrix uses a pointer to the\n",
        " *  data of M. The data is not copied to a new location.\n",
        " *  If M is destroyed, this matrix is useless.\n",
        " */\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b);\n",
        "\n",
        "/** Copy data from matrix on device to host\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy data from matrix on host to device\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from device to host, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from host to device, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host);\n",
        "\n",
        "/** Free data memory on host.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "\n",
        "/** Free data memory on device.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Input and Output\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host.\n",
        " *  If nb<0, print all rows.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device.\n",
        " *  If nb<0, print all rows.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print a matrix to a csv file.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat);\n",
        "\n",
        "/** Read a matrix from a csv file.\n",
        " *\n",
        " *  This version creates the matrix on the host first.\n",
        " */\n",
        "fmatrix fmatrix_device_from_csv(const char* filename);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Useful\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Create a matrix with random values between -1 and 1\n",
        " *  on the device */\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols);\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGwZ36ifWQ-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80854ca0-eb9d-47e7-f41e-534f937d84f6"
      },
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "// for reading CSV files, we use some C++\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "\n",
        "int fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "int fmatrix_size(fmatrix mat) {\n",
        "//    fmatrix_assert(mat);\n",
        "     return fmatrix_elements(mat) * sizeof(float);\n",
        "}\n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat));\n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk(\n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat))\n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_device.data, mat_host.data,\n",
        "                   fmatrix_size(mat_host),\n",
        "                   cudaMemcpyHostToDevice\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,\n",
        "                   fmatrix_size(mat_device),\n",
        "                   cudaMemcpyDeviceToHost\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_device);\n",
        "    fmatrix mat_host = fmatrix_create_on_host(mat_device.rows, mat_device.cols);\n",
        "    fmatrix_data_to_host(mat_host,mat_device);\n",
        "    return mat_host;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix mat_device = fmatrix_create_on_device(mat_host.rows, mat_host.cols);\n",
        "    fmatrix_data_to_device(mat_host,mat_device);\n",
        "    return mat_device;\n",
        "}\n",
        "\n",
        "/** We could do it like this, but it would not set our pointer M.data to 0.\n",
        "... fmatrix_free_on_host(M)\n",
        "void fmatrix_free_on_host(fmatrix mat) {\n",
        "    fmatrix_assert(mat);\n",
        "  free(mat.data);\n",
        "  mat.data = 0;\n",
        "  mat.cols = 0;\n",
        "  mat.rows = 0;\n",
        "}\n",
        "*/\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b) {\n",
        "    fmatrix_assert(M);\n",
        "    fmatrix A = {\n",
        "        .data = &getfm(M,0,a),\n",
        "        .cols = b-a,\n",
        "        .rows = M.rows\n",
        "    };\n",
        "    fmatrix_assert(A);\n",
        "    return A;\n",
        "}\n",
        "\n",
        "\n",
        "__host__\n",
        "__device__\n",
        "void fmatrix_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "   fmatrix_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat) {\n",
        "  // Open file\n",
        "  FILE* fp = fopen(filename, \"w\");\n",
        "  // allocate copy\n",
        "  fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "  for (int i = 0 ; i < tmp.rows; i++){\n",
        "    for (int j = 0 ; j<tmp.cols; j++){\n",
        "      // Note: %.15g gives 15 significant digits (full double precision)\n",
        "      fprintf(fp,\"%.15g\", getfm(tmp,i,j));\n",
        "      if (j+1<tmp.cols) {\n",
        "        fprintf(fp,\",\");\n",
        "      }\n",
        "    }\n",
        "    fprintf(fp,\"\\n\");\n",
        "  }\n",
        "  fmatrix_free_on_host(&tmp);\n",
        "  // Close file\n",
        "  fclose(fp);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_create_random_on_device_kernel(fmatrix M) {\n",
        "    // choose a seed (here: the same each launch)\n",
        "    unsigned long seed = 0;\n",
        "    int sequence = 0;\n",
        "    // first, initialize the random numbers\n",
        "    curandState state;\n",
        "    curand_init(seed, sequence, 0, &state);\n",
        "    for (int i = 0; i < fmatrix_elements(M); ++i) {\n",
        "        // curand_uniform creates numbers between 0 and 1\n",
        "        M.data[i] = (curand_uniform(&state)-0.5)*2.0;\n",
        "    }\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols) {\n",
        "    // Create an uninitialized matrix on the device\n",
        "    fmatrix M = fmatrix_create_on_device(rows,cols);\n",
        "    // Call a kernel with a single thread to fill the values\n",
        "    fmatrix_create_random_on_device_kernel<<<1,1>>>(M);\n",
        "\n",
        "    return M;\n",
        "}\n",
        "\n",
        "/* Count the number of rows and columns in a csv files (without headers) */\n",
        "void count_elements_in_csv(const char* filename, int* rows, int* cols) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "\n",
        "  *rows = 0;\n",
        "  *cols = 0;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int tempcols = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "          ++tempcols;\n",
        "        }\n",
        "        if (tempcols > *cols) {\n",
        "           *cols = tempcols;\n",
        "        }\n",
        "        ++(*rows);\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "/** Read the data from a csv file into an fmatrix on the host.\n",
        " *  Careful: We assume that the matrix has the right dimensions!\n",
        " *  Use count_elements_in_csv(...) to get the dimensions if\n",
        " *  unknown.\n",
        " */\n",
        "void fmatrix_fill_from_csv(fmatrix h_M,const char* filename) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int col = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "\t\t\t\t\tgetfm(h_M,row,col) = strtod(value.c_str(), NULL);\n",
        "          ++col;\n",
        "\t\t\t\t}\n",
        "        ++row;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_device_from_csv(const char* filename) {\n",
        "  // first read the file to count the number of elements\n",
        "  int rows = 0;\n",
        "  int cols = 0;\n",
        "  count_elements_in_csv(filename,&rows,&cols);\n",
        "\n",
        "  // allocate the matrix on the host\n",
        "  fmatrix h_M = fmatrix_create_on_host(rows,cols);\n",
        "\n",
        "  // read the data into the host matrix\n",
        "  fmatrix_fill_from_csv(h_M,filename);\n",
        "\n",
        "  // copy the matrix to the device\n",
        "  fmatrix M = fmatrix_copy_to_device(h_M);\n",
        "\n",
        "  // destroy the host matrix\n",
        "  fmatrix_free_on_host(&h_M);\n",
        "\n",
        "  return M;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKLTK8ELOdN"
      },
      "source": [
        "## Data I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD7rmOBmWfsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e027116e-58b6-45a1-9cb9-f98766a2da71"
      },
      "source": [
        "%%writefile read_csv.cuh\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef read_csv_H\n",
        "#define read_csv_H\n",
        "\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol);\n",
        "\n",
        "#endif"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting read_csv.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeedFsZ_WQx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4e6513-bc4e-4d70-f472-6b774065d20a"
      },
      "source": [
        "%%writefile read_csv.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"cuda_stuff.cuh\" // for matrix indexing\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for reading the dataset from a file\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Read a csv file with a given number of rows and columns */\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol) {\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  double ioTemp;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row_count = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "      // read the headers (and discard)\n",
        "\t\t\tgetline(infile, row_as_string, '\\n');\n",
        "      cout << \"headers: \" << row_as_string << \"!\" << std::endl;\n",
        "      for(int i = 0; i < nbrow; i++){\n",
        "  \t\t\tgetline(infile, row_as_string, '\\n');\n",
        "        // cout << \"read line \" << row_as_string << \"!\" << std::endl;\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "\t\t\t  for(int j = 0; j < nbcol; j++){\n",
        "          getline(line_stream, value, ',');\n",
        "\t\t\t\t\tioTemp = strtod(value.c_str(), NULL);\n",
        "          // cout << \"(\"<<i<<\",\"<<j<<\") = \"<< ioTemp << std::endl;\n",
        "\n",
        "\t\t\t\t\tdata_array[IDX2C(i,j,nbrow)] = ioTemp;\n",
        "\n",
        "\t\t\t\t}\n",
        "        ++row_count;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "    cout << \"Read \" << row_count << \" rows.\" << std::endl;\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting read_csv.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8ilQdYYroU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd16c468-530c-44ee-d29d-8d2255280a98"
      },
      "source": [
        "%%writefile preprocess_data.cuh\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef preprocess_data_H\n",
        "#define preprocess_data_H\n",
        "\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels );\n",
        "\n",
        "#endif"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting preprocess_data.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaeUdw_KYaCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e358774-66bf-420f-d688-2a7236836b3b"
      },
      "source": [
        "%%writefile preprocess_data.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"preprocess_data.cuh\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   ld = number of rows\n",
        "   Example of use: a[IDX2C(0, 1, 50)] */\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for preprocessing the data set\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Split data into inputs and labels. Allocated memory for inputs and labels.\n",
        "   Since cuBLAS is column major, each input is in a column.\n",
        "   We also add 1.0 as first element to each input vector.\n",
        "*/\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels ) {\n",
        "    // The inputs are the first nbrows-1 columns.\n",
        "    // The labels are the last column (index nbrows-1), booleanized\n",
        "    // by the condition >= above_threshold\n",
        "    *input_array = (float *)malloc(nbrows * nb_inputs * sizeof(float));\n",
        "    *label_array = (float *)malloc(nbrows * nb_labels * sizeof(float));\n",
        "    //cout << &input_array << \" and \"<< &label_array << \" data \" << data_array << std::endl;\n",
        "    cout << \"Allocated memory for inputs: \" << nbrows << \" rows, \"<< nb_inputs << \" columns.\" << std::endl;\n",
        "    cout << \"Allocated memory for labels: \" << nbrows << \" rows, \"<< nb_labels << \" columns.\" << std::endl;\n",
        "\n",
        "    // Copy the data to X\n",
        "    for(int i = 0; i < nbrows; i++){\n",
        "      // Set the first element of each x to 1\n",
        "      (*input_array)[IDX2C(0,i,nb_inputs)] = 1.0;\n",
        "      // Copy the rest of x\n",
        "\t\t\tfor(int j = 1; j < nb_inputs; j++){\n",
        "\t\t\t\t(*input_array)[IDX2C(j,i,nb_inputs)] = data_array[IDX2C(i,j-1,nbrows)];\n",
        "\t\t\t}\n",
        "      float median_house_value = data_array[IDX2C(i,nbcols-1,nbrows)];\n",
        "      (*label_array)[IDX2C(0,i,nb_labels)] = 0.0;\n",
        "      (*label_array)[IDX2C(1,i,nb_labels)] = 0.0;\n",
        "      if (median_house_value >= above_threshold) {\n",
        "        (*label_array)[IDX2C(0,i,nb_labels)] = 1.0;\n",
        "      } else {\n",
        "        (*label_array)[IDX2C(1,i,nb_labels)] = 1.0;\n",
        "      }\n",
        "\t\t}\n",
        "\n",
        "    // Show some entries for double checking\n",
        "    cout << \"Inputs (first \"<<print_rows<<\"):\" << std::endl;\n",
        "\t  for(int j = 0; j < nb_inputs; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*input_array)[IDX2C(j,i,nb_inputs)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "    cout << \"Labels (first \"<<print_rows<<\"):\" << std::endl;\n",
        "    for(int j = 0; j < nb_labels; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*label_array)[IDX2C(j,i,nb_labels)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting preprocess_data.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHy3EAid05oA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code That You Write"
      ],
      "metadata": {
        "id": "rR-9WFucUWLC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWS3hlAecOc"
      },
      "source": [
        "## Classifier Math"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_tmB-xbZKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0013f94-dffb-470f-c588-256d260abe85"
      },
      "source": [
        "%%writefile classifier_math.cuh\n",
        "#ifndef classifier_math_H\n",
        "#define classifier_math_H\n",
        "\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "/** Returns a random float between min and max (including). */\n",
        "float float_rand( float min, float max );\n",
        "\n",
        "/** Initialize W with Xavier's method,\n",
        " *  scaled by a. */\n",
        "void xavier_weight_init(float a, fmatrix W);\n",
        "\n",
        "/** Compute the softmax for each column of Z and store in P **/\n",
        "void softmax_col(fmatrix P,fmatrix Z);\n",
        "\n",
        "///////////////////////////////////\n",
        "// TO BE COMPLETED\n",
        "// ... add your matrix math here\n",
        "///////////////////////////////////\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "#endif"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting classifier_math.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgXwgv6Bbo-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "609b237c-6274-4090-ea6e-ec9182ed6199"
      },
      "source": [
        "%%writefile classifier_math.cu\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Auxiliary function\n",
        "/////////////////////////////////////////////////////////\n",
        "// generate random numbers in interval [min,max]\n",
        "float float_rand( float min, float max )\n",
        "{\n",
        "    float scale = rand() / (float) RAND_MAX; /* [0, 1.0] */\n",
        "    return min + scale * ( max - min );      /* [min, max] */\n",
        "}\n",
        "\n",
        "void xavier_weight_init(float a, fmatrix W){\n",
        "    for (int j = 0; j < W.rows  ; ++j) {\n",
        "      for (int i = 0; i < W.cols  ; ++i) {\n",
        "          getfm(W,j,i) = a * (1.0/sqrt(W.cols+W.rows)) * float_rand(-1.0,1.0);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void softmax_col(fmatrix P,fmatrix Z) {\n",
        "    assert(P.cols==Z.cols);\n",
        "    assert(P.rows==Z.rows);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the softmax here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_multiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.cols; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,i,k)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.rows);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.cols == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Multiplication de matrice avec transpos√©\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_tmultiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.rows; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,k,i)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.cols);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.rows == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting classifier_math.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6G22rDKR3rv"
      },
      "source": [
        "## Evaluating Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7Vmzo72hpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50039be-1e50-475e-d63b-0b578cd5960c"
      },
      "source": [
        "%%writefile evaluate_accuracy.cuh\n",
        "\n",
        "/** Evaluate the accuracy of a linear classifier with D x M weight\n",
        " *  matrix W, using D x N input data X and M x N output labels Y.\n",
        " *  Z is a temporary matrix with dimensions M x N,\n",
        " *  which must be previously allocated.\n",
        " */\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z);\n",
        "\n",
        "/** Compute the logloss given M x N matrices of\n",
        " *  probabilities P and output labels Y\n",
        " *  and stores it in J.\n",
        " *  J is a matrix with dimensions 1 x 1,\n",
        " *  which must be previously allocated.\n",
        " *  logloss = sum_j -Y(j,k)*log(P(j,k))\n",
        " */\n",
        "float evaluate_logloss(fmatrix d_P,fmatrix d_Y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate_accuracy.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Z-9B4a2dwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5dddbf-a347-4d00-9faa-9a20937830fb"
      },
      "source": [
        "%%writefile evaluate_accuracy.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__\n",
        "void evaluate_accuracy_kernel(fmatrix d_Y,fmatrix d_Z,int* count) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    if (idx < d_Z.cols){\n",
        "        float z_max = getfm(d_Z,0,idx);\n",
        "        int i_max = 0;\n",
        "        for (int i = 1; i < d_Z.rows; ++i) {\n",
        "          if (getfm(d_Z,i,idx)>z_max) {\n",
        "                z_max = getfm(d_Z,i,idx);\n",
        "                i_max = i;\n",
        "          }\n",
        "        }\n",
        "      if (getfm(d_Y,i_max,idx)>=0.5f) {\n",
        "          atomicAdd(count,1);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z) {\n",
        "    assert(d_Y.cols == d_Z.cols);\n",
        "    assert(d_Y.rows == d_Z.rows);\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 1. compute Z = W^T X\n",
        "  // --> each column of Z corresponds to one input\n",
        "  //////////////////////////////////////////\n",
        "\n",
        "  /*********************************\n",
        "  / TO BE COMPLETED\n",
        "  / ... compute Z = W^T X here ...\n",
        "  **********************************/\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 2. For each column z of Z,\n",
        "  // find argmax_k z_k\n",
        "  //////////////////////////////////////////\n",
        "\n",
        "  int true_class = 0;\n",
        "\n",
        "  int* d_count = 0;\n",
        "  gpuErrchk(cudaMalloc((void **)&d_count, sizeof(int)));\n",
        "  gpuErrchk(\n",
        "        cudaMemcpy( d_count, &true_class, sizeof(int), cudaMemcpyHostToDevice )\n",
        "  );\n",
        "\n",
        "    int threadsPerBlock = d_Z.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    evaluate_accuracy_kernel<<< blocksPerGrid, threadsPerBlock >>>(d_Y,d_Z,d_count);\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "  gpuErrchk(\n",
        "          cudaMemcpy(&true_class, d_count, sizeof(int), cudaMemcpyDeviceToHost )\n",
        "  );\n",
        "\n",
        "  //printf(\"Correct results: %d out of %d\\n\",true_class,nb_tested);\n",
        "  //printf(\"Accuracy: %f\\n\",(float)true_class/(float)nb_tested);\n",
        "  return (float)true_class/(float)d_Z.cols;\n",
        "}\n",
        "\n",
        "\n",
        "float evaluate_logloss(fmatrix d_P,fmatrix d_Y) {\n",
        "    assert(d_Y.cols == d_P.cols);\n",
        "    assert(d_Y.rows == d_P.rows);\n",
        "\n",
        "  float J = 0.0;\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the logloss here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "  return J;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate_accuracy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AwZh8WULi_F"
      },
      "source": [
        "## Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWO5p1NeHE9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706b3eb8-8289-4b1a-e158-10079812a309"
      },
      "source": [
        "%%writefile linear_classification.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"preprocess_data.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"evaluate_accuracy.cuh\"\n",
        "/* Includes, cuda */\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "/////////////////////////////////////////////////////////\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    size_t N_train = 4; //12000; // points for training (Google: 12000)\n",
        "    size_t N_test = 2; // 5000; // points for validation (Google: 5000)\n",
        "    size_t N = N_train;\n",
        "    size_t Nall = N_train+N_test;\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Reading the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    fmatrix alldata = fmatrix_create_on_host(Nall,data_columns);\n",
        "    read_csv(\"sample_data/california_housing_train.csv\",alldata.data,Nall,data_columns);\n",
        "    //fmatrix_print(alldata);\n",
        "\n",
        "    size_t D = data_columns-1+1; // remove output column, add column with const. 1.0\n",
        "    size_t M = 2; // number of labels (one-hot encoding)\n",
        "    fmatrix Xall = fmatrix_create_on_host(D,Nall);\n",
        "    fmatrix Yall = fmatrix_create_on_host(M,Nall);\n",
        "    get_inputs_and_labels(alldata.data,&Xall.data,&Yall.data,Nall,data_columns,D,M);\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Inputs and labels are now available in X and Y.\n",
        "    // Each input is a column in X; X is of dimension D x N\n",
        "    // each label is a column in Y; Y is of dimension M x N\n",
        "    /////////////////////////////////////////////////////////\n",
        "\n",
        "    // Logfile\n",
        "    FILE* fp = fopen(\"log.txt\", \"w\");\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for Stochastic Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    int nb_iter = 10;           // defeault: 10;\n",
        "    int periods = nb_iter;      // reporting period\n",
        "    int batch_size = N;         // defeault: N;\n",
        "    float learning_rate = 1e-7; // default: 1e-7\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Memory Allocation and Initialization\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // take X,Y to be the first N columns of all data\n",
        "    fmatrix h_X = fmatrix_subcolumns(Xall,0,N);\n",
        "    fmatrix h_Y = fmatrix_subcolumns(Yall,0,N);\n",
        "    fmatrix h_Xtest = fmatrix_subcolumns(Xall,N,Nall);\n",
        "    fmatrix h_Ytest = fmatrix_subcolumns(Yall,N,Nall);\n",
        "    fmatrix h_W = fmatrix_create_on_host(D,M);\n",
        "    fmatrix h_J = fmatrix_create_on_host(1,1);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Initializing Weight Matrix\n",
        "    // its dimension is D x M\n",
        "    /////////////////////////////////////////////////////////\n",
        "    xavier_weight_init(1.0,h_W);\n",
        "\n",
        "    //////////////////////////////\n",
        "    // Copy data to device      //\n",
        "    //////////////////////////////\n",
        "    fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "    fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "    fmatrix d_Xtest = fmatrix_copy_to_device(h_Xtest);\n",
        "    fmatrix d_Ytest = fmatrix_copy_to_device(h_Ytest);\n",
        "    fmatrix d_W = fmatrix_copy_to_device(h_W);\n",
        "    fmatrix d_J = fmatrix_copy_to_device(h_J);\n",
        "\n",
        "    /////////////////////////////////////////\n",
        "    // Create auxiliary matrices on device //\n",
        "    /////////////////////////////////////////\n",
        "    fmatrix d_Z = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_P = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_G = fmatrix_create_on_device(D,M);\n",
        "    // auxiliary matrix for computing Z=W^T X on test data\n",
        "    fmatrix d_Ztest = fmatrix_create_on_device(M,d_Xtest.cols);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Batch Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    //fmatrix_device_print(d_X);\n",
        "    //fmatrix_device_print(d_W);\n",
        "\n",
        "     /* Evaluate the accuracy */\n",
        "    float accuracy = 0;\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"initial accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    float J = 0;\n",
        "\n",
        "    clock_t tstart_total, tend;\n",
        "    tstart_total = clock();\n",
        "\n",
        "    int batch_pointer = 0;\n",
        "    for (int i = 0; i < nb_iter; ++i ) {\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // compute Z = W^T X\n",
        "      // --> each column z of Z corresponds to one column x of X\n",
        "      ////////////////////////////////\n",
        "\n",
        "////      /* Compute A = f*B^T*C */\n",
        "//// void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "      fmatrix_tmult(d_Z,1.0,d_W,d_X);\n",
        "\n",
        "      fmatrix_device_print(d_W);\n",
        "      fmatrix_device_print(d_X);\n",
        "      fmatrix_device_print(d_Z);\n",
        "\n",
        "      ///////////////////////////////////\n",
        "      // TO BE COMPLETED\n",
        "      ///////////////////////////////////\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // For each column z of Z, compute activation p(z);\n",
        "      // then update W\n",
        "      ////////////////////////////////\n",
        "\n",
        "      // compute softmax per column of Z and store in Z\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    ///////////////////////////////////\n",
        "\n",
        "      // evaluate logloss (for reporting only)\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    ///////////////////////////////////\n",
        "\n",
        "      // Q:=P-Y\n",
        "      // compute gradient G = XQ^T\n",
        "      // ... possibly work with G here ...\n",
        "      // update weights W = W - learning_rate*G\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    ///////////////////////////////////\n",
        "\n",
        "      //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // For reporting, compute logloss and accuracy\n",
        "      ////////////////////////////////\n",
        "      if (i%(nb_iter/periods)==0) {\n",
        "        float accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "        printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
        "        fprintf(fp, \"%f,%f\\n\", J, accuracy);\n",
        "      }\n",
        "\n",
        "    }\n",
        "    tend = clock();\n",
        "    float duration = ((float)(tend-tstart_total))/CLOCKS_PER_SEC;\n",
        "    printf(\"Duration (s): %f\\n\",duration);\n",
        "    /* Evaluate the accuracy */\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"final accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    printf(\"final weights: \\n\");\n",
        "    fmatrix_device_print(d_W);\n",
        "\n",
        "    /* Memory clean up */\n",
        "    /** No need to free h_X, h_Y, h_Xtest, h_Ytest since\n",
        "     *  they all point to Xall\n",
        "     */\n",
        "    fmatrix_free_on_host(&h_W);\n",
        "    fmatrix_free_on_host(&Xall);\n",
        "    fmatrix_free_on_host(&Yall);\n",
        "\n",
        "    fmatrix_free_on_device(&d_X);\n",
        "    fmatrix_free_on_device(&d_Y);\n",
        "    fmatrix_free_on_device(&d_Xtest);\n",
        "    fmatrix_free_on_device(&d_Ytest);\n",
        "    fmatrix_free_on_device(&d_W);\n",
        "    fmatrix_free_on_device(&d_Z);\n",
        "    fmatrix_free_on_device(&d_J);\n",
        "\n",
        "    // Close log file\n",
        "    fclose(fp);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting linear_classification.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrATC8s9LsDw"
      },
      "source": [
        "# Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z52xd0NMRKXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6c15b0-a276-4409-b137-1cd4c78f82fd"
      },
      "source": [
        "!nvcc -arch=sm_35 -Wno-deprecated-gpu-targets -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(76)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"learning_rate\"\u001b[0m was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(130)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"batch_pointer\"\u001b[0m was declared but never referenced\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZVqTfXcLvPr"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GcUSYjJ1EEx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV_vFkIT7fV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00cb9d44-a7ae-48b6-abc5-b22b60c1ab43"
      },
      "source": [
        "%%time\n",
        "!./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 6 rows.\n",
            "Allocated memory for inputs: 6 rows, 9 columns.\n",
            "Allocated memory for labels: 6 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t\n",
            "15\t19\t17\t14\t20\t29\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t\n",
            "1283\t1901\t174\t337\t326\t236\t\n",
            "1015\t1129\t333\t515\t624\t671\t\n",
            "472\t463\t117\t226\t262\t239\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 0, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 1, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 2, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 3, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 4, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 5, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 6, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 7, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 8, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "7.485487,\t7.495677,\t7.501409,\t7.502046;\n",
            "-20.401211,\t-20.430006,\t-20.446203,\t-20.448004\n",
            "]\n",
            "iter: 9, logloss: 0.000000, accuracy: 0.000000\n",
            "Duration (s): 0.002064\n",
            "final accuracy: 0.000000\n",
            "final weights: \n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "CPU times: user 18.5 ms, sys: 7.67 ms, total: 26.2 ms\n",
            "Wall time: 1.02 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIyxh0ClrIz"
      },
      "source": [
        "Let's plot the logloss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR2kCNEIlpqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c1136880-8a61-40b2-b59d-a7b77599144a"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('log.txt',sep=',',header=None)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data[0],label=\"logloss\")\n",
        "ax2=ax.twinx()\n",
        "ax2.plot([], [])\n",
        "ax2.plot(data[1],label=\"accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAD4CAYAAAC5S3KDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPEElEQVR4nO3cf4zk9V3H8eeLWw+PqeFXUop3NHeRi/Vao9QLbW00TaHtEW2PKDFg1ItWL8ai/aGp1zYRpDVptZZqSk1WoCHYFAjWeGlVpFD+MRW5QpP2+BFOqL27QqlAsezV4tq3f+z3YFj3uN2d2f1+tvN8JJub7/f72Zn3TeDzvJnZbKoKSZJac0LfA0iStBADJUlqkoGSJDXJQEmSmmSgJElNmup7gOU44YQTasOGDX2PIUlrypEjR6qq1swLkzUZqA0bNjAzM9P3GJK0piT5Tt8zLMWaKakkabIYKElSkwyUJKlJBkqS1CQDJUlqkoGSJDXJQEmSmmSgJElNMlCSpCYZKElSkwyUJKlJBkqS1CQDJUlqkoGSJDXJQEmSmmSgJElNMlCSpCYZKElSkwyUJKlJBkqS1CQDJUlqkoGSJDXJQEmSmmSgJElNMlCSpCaNJVBJdiR5IMmBJHsWuH5ikhu763cm2Tzv+kuTPJ3kD8YxjyRp6Vrby0cOVJJ1wFXABcA24JIk2+YteyvwZFWdDVwJfGje9Y8A/zjqLJKk5WlxLx/HK6hzgQNV9VBVPQPcAOyct2YncF13+2bgvCQBSHIh8DCwfwyzSJKWp7m9fByB2ggcHDo+1J1bcE1VzQJPAacneRHwh8AfH+9BkuxOsi/JvtnZ2TGMLUkTZ+roPtp97R66tip7+ZKGHeedLcPlwJVV9XQX4WOqqmlgGmAwGNTKjyZJ33dmq2r7Ctzv5SxyL1+KcQTqMHDW0PGm7txCaw4lmQJOBh4HXgVclORPgVOA7yX576r62BjmkiQtXnN7+TgCdRewNckW5oa/GPjleWv2AruALwAXAbdXVQE/c3RBksuBp42TJPWiub185EBV1WySS4FbgHXAtVW1P8kVwL6q2gtcA1yf5ADwBHN/cUlSI1rcyzMXv7VlMBjUzMxM32NI0pqS5EhVDfqeY7H8TRKSpCYZKElSkwyUJKlJBkqS1CQDJUlqkoGSJDXJQEmSmmSgJElNMlCSpCYZKElSkwyUJKlJBkqS1CQDJUlqkoGSJDXJQEmSmmSgJElNMlCSpCYZKElSkwyUJKlJBkqS1CQDJUlqkoGSJDXJQEmSmmSgJElNMlCSpCYZKElSkwyUJKlJBkqS1CQDJUlqkoGSJDVpLIFKsiPJA0kOJNmzwPUTk9zYXb8zyebu/BuSfDHJl7s/Xz+OeSRJS9faXj5yoJKsA64CLgC2AZck2TZv2VuBJ6vqbOBK4EPd+f8E3lxVPw7sAq4fdR5J0tK1uJeP4xXUucCBqnqoqp4BbgB2zluzE7iuu30zcF6SVNU9VfX17vx+YEOSE8cwkyRpaZrby8cRqI3AwaHjQ925BddU1SzwFHD6vDW/CNxdVd8dw0ySpKVpbi+fGvUOxiHJy5l7qfjGF1izG9gNsH79+lWaTJK+r0wl2Td0PF1V0+O688Xs5UsxjkAdBs4aOt7UnVtozaEkU8DJwOMASTYBfwf8WlX9+7EepHsSpwEGg0GNYW5JmjSzVbX9GNdWZS9finG8xXcXsDXJliTrgYuBvfPW7GXugzOAi4Dbq6qSnAJ8FthTVf8yhlkkScvT3F4+cqC69yEvBW4B7gNuqqr9Sa5I8pZu2TXA6UkOAO8Cjv744qXA2cAfJflS9/XiUWeSJC1Ni3t5qtbeu2WDwaBmZmb6HkOS1pQkR6pq0Pcci+VvkpAkNclASZKaZKAkSU0yUJKkJhkoSVKTDJQkqUkGSpLUJAMlSWqSgZIkNclASZKaZKAkSU0yUJKkJhkoSVKTDJQkqUkGSpLUJAMlSWqSgZIkNclASZKaZKAkSU0yUJKkJhkoSVKTDJQkqUkGSpLUJAMlSWqSgZIkNclASZKaZKAkSU0yUJKkJhkoSVKTDJQkqUkGSpLUpLEEKsmOJA8kOZBkzwLXT0xyY3f9ziSbh669pzv/QJI3jWMeSdLStbaXjxyoJOuAq4ALgG3AJUm2zVv2VuDJqjobuBL4UPe924CLgZcDO4CPd/cnSVpFLe7lU6PeAXAucKCqHgJIcgOwE7h3aM1O4PLu9s3Ax5KkO39DVX0XeDjJge7+vjCGuf6ff/34b/FD37pvJe5aklbct0/5MV79O3+9Unff3F4+jrf4NgIHh44PdecWXFNVs8BTwOmL/F4AkuxOsi/JvtnZ2TGMLUkTZ+roPtp97R66tip7+ZKGHfUOVktVTQPTAIPBoJZzHyv4Lw9JWgtmq2p730Ms1jheQR0Gzho63tSdW3BNkingZODxRX6vJGnlNbeXjyNQdwFbk2xJsp65D8r2zluzF9jV3b4IuL2qqjt/cfeTIVuArcC/jWEmSdLSNLeXj/wWX1XNJrkUuAVYB1xbVfuTXAHsq6q9wDXA9d0HZ08w9xenW3cTcx/CzQJvq6r/HXUmSdLStLiXZy5+a8tgMKiZmZm+x5CkNSXJkaoa9D3HYvmbJCRJTTJQkqQmGShJUpMMlCSpSQZKktQkAyVJapKBkiQ1yUBJkppkoCRJTTJQkqQmGShJUpMMlCSpSQZKktQkAyVJapKBkiQ1yUBJkppkoCRJTTJQkqQmGShJUpMMlCSpSQZKktQkAyVJapKBkiQ1yUBJkppkoCRJTTJQkqQmGShJUpMMlCSpSQZKktQkAyVJatJIgUpyWpJbkzzY/XnqMdbt6tY8mGRXd+6kJJ9Ncn+S/Uk+OMoskqSV08d+P+orqD3AbVW1FbitO54/7GnAZcCrgHOBy4b+Yh+uqpcB5wCvTXLBiPNIklbGqu/3owZqJ3Bdd/s64MIF1rwJuLWqnqiqJ4FbgR1VdaSqPg9QVc8AdwObRpxHkrQyVn2/HzVQZ1TVI93tR4EzFlizETg4dHyoO/esJKcAb2auypKk9qz6fj91vAVJPge8ZIFL7xs+qKpKUse7vwXufwr4FPCXVfXQC6zbDewGWL9+/VIfRpIEU0n2DR1PV9X00YNW9vtnhz3egqo6/wUe7BtJzqyqR5KcCTy2wLLDwOuGjjcBdwwdTwMPVtVHjzPHdLeWwWCw5CdGksRsVW0/1sVW9vujRn2Lby+wq7u9C/j7BdbcArwxyandh2Vv7M6R5APAycA7RpxDkrSyVn2/T9XyX4wkOR24CXgp8B/AL1XVE0m2A79dVb/ZrfsN4L3dt/1JVX0iySbm3qu8H/hud+1jVXX18R53MBjUzMzMsueWpEmU5EhVDZb5vau+348UqL4YKElaulEC1Qd/k4QkqUkGSpLUJAMlSWqSgZIkNclASZKaZKAkSU0yUJKkJhkoSVKTDJQkqUkGSpLUJAMlSWqSgZIkNclASZKaZKAkSU0yUJKkJhkoSVKTDJQkqUkGSpLUJAMlSWqSgZIkNclASZKaZKAkSU0yUJKkJhkoSVKTDJQkqUkGSpLUJAMlSWqSgZIkNclASZKaZKAkSU0yUJKkJo0UqCSnJbk1yYPdn6ceY92ubs2DSXYtcH1vkq+MMoskaeX0sd+P+gpqD3BbVW0FbuuO5w9zGnAZ8CrgXOCy4b9Ykl8Anh5xDknSylr1/X7UQO0ErutuXwdcuMCaNwG3VtUTVfUkcCuwAyDJi4B3AR8YcQ5J0spa9f1+apRpgTOq6pHu9qPAGQus2QgcHDo+1J0DeD/w58CR4z1Qkt3AboD169cvd15JmmRTSfYNHU9X1fQiv3fV9vtnhz3egiSfA16ywKX3DR9UVSWpxT5wkp8EfqSq3plk8/HWd0/iNMBgMFj040iSnjVbVduPdbGV/f6o4waqqs5/gQf9RpIzq+qRJGcCjy2w7DDwuqHjTcAdwGuA7Um+2s3x4iR3VNXrkCStutb2+1Qt/8VIkj8DHq+qDybZA5xWVe+et+Y04IvAK7tTdwM/VVVPDK3ZDHymql6xmMcdDAY1MzOz7LklaRIlOVJVg2V+76rv96P+kMQHgTckeRA4vzsmyfYkVwN0g70fuKv7umJ4WEnSmrDq+/1Ir6D64isoSVq6UV5B9cHfJCFJapKBkiQ1yUBJkppkoCRJTTJQkqQmGShJUpMMlCSpSQZKktQkAyVJapKBkiQ1yUBJkppkoCRJTTJQkqQmGShJUpMMlCSpSQZKktQkAyVJapKBkiQ1yUBJkppkoCRJTTJQkqQmGShJUpMMlCSpSQZKktSkVFXfMyxZku8B31nmt08Bs2McZ63z+XiOz8Xz+Xw85/vludhQVWvmhcmaDNQokuyrqu19z9EKn4/n+Fw8n8/Hc3wu+rFmSipJmiwGSpLUpEkM1HTfAzTG5+M5PhfP5/PxHJ+LHkzcZ1CSpLVhEl9BSZLWAAMlSWrSxAQqyY4kDyQ5kGRP3/P0KclZST6f5N4k+5O8ve+ZWpBkXZJ7knym71n6lOSUJDcnuT/JfUle0/dMfUryzu7/k68k+VSSH+x7pkkxEYFKsg64CrgA2AZckmRbv1P1ahb4/araBrwaeNuEPx9HvR24r+8hGvAXwD9V1cuAn2CCn5MkG4HfA7ZX1SuAdcDF/U41OSYiUMC5wIGqeqiqngFuAHb2PFNvquqRqrq7u/1t5jagjf1O1a8km4CfA67ue5Y+JTkZ+FngGoCqeqaqvtXrUP2bAjYkmQJOAr7e8zwTY1ICtRE4OHR8iAnfkI9Kshk4B7iz51H69lHg3cD3ep6jb1uAbwKf6N7uvDrJoO+h+lJVh4EPA18DHgGeqqp/7neqyTEpgdICkrwI+FvgHVX1X33P05ckPw88VlVf7HuWBkwBrwT+qqrOAWaAif3MNsmpzL3bsgX4YWCQ5Ff6nWpyTEqgDgNnDR1v6s5NrCQ/wFycPllVn+57np69FnhLkq8y9/bv65P8Tb8j9eYQcKiqjr6ivpm5YE2q84GHq+qbVfU/wKeBn+55pokxKYG6C9iaZEuS9cx9yLm355l6kyTMfcZwX1V9pO95+lZV76mqTVW1mbn/Nm6vqon8V3JVPQocTPKj3anzgHt7HKlvXwNeneSk7v+b85jgHxpZbVN9D7Aaqmo2yaXALcz9FM61VbW/57H69FrgV4EvJ/lSd+69VfUP/Y2khvwu8MnuH3MPAb/e8zy9qao7k9wM3M3cT7/eg7/2aNX4q44kSU2alLf4JElrjIGSJDXJQEmSmmSgJElNMlCSpCYZKElSkwyUJKlJ/wcYYUpg/I2N+wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aUKkNJqTDZ"
      },
      "source": [
        "# Debugging\n",
        "Compile with debugging info on the host (`-g`) and device (`-G`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dtB5QKcWQ5M2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcfLGo1UrMq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241cd71d-97e6-41be-fd9f-51838620a247"
      },
      "source": [
        "!nvcc -g -G -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(76)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"learning_rate\"\u001b[0m was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(130)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"batch_pointer\"\u001b[0m was declared but never referenced\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuaGO10rRm9"
      },
      "source": [
        "Run the debugger cuda-gdb, stopping at the first error that is detected. Shows first the call stack on the GPU, the values of local variables, then the call stack on the host (thread 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ8nAtzGTRgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7caff4da-8a5b-40ce-ffe8-944dc41c7afb"
      },
      "source": [
        "! printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "! cat tmp.txt\n",
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set cuda memcheck on\n",
            "set cuda api_failures stop\n",
            "catch throw\n",
            "r\n",
            "bt\n",
            "info locals\n",
            "thread 1\n",
            "bt\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[New Thread 0x7fad67250000 (LWP 6223)]\n",
            "[Detaching after fork from child process 6224]\n",
            "[New Thread 0x7fad66723000 (LWP 6233)]\n",
            "[New Thread 0x7fad65f22000 (LWP 6234)]\n",
            "original matrix:\n",
            "[\n",
            "0.480439;\n",
            "-0.123098\n",
            "]\n",
            "[\n",
            "0.480439\n",
            "]\n",
            "a.out: classifier_math.cu:111: void fmatrix_tmult(fmatrix, float, fmatrix, fmatrix): Assertion `A.rows == B.cols' failed.\n",
            "\n",
            "Thread 1 \"a.out\" received signal SIGABRT, Aborted.\n",
            "0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#1  0x00007fad69a17859 in abort () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#2  0x00007fad69a17729 in ?? () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#3  0x00007fad69a28fd6 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#4  0x00005652aac0a584 in fmatrix_tmult (A=..., f=1, B=..., C=...) at classifier_math.cu:111\n",
            "#5  0x00005652aac0a7c7 in main () at test.cu:13\n",
            "No symbol table info available.\n",
            "[Switching to thread 1 (Thread 0x7fad699f2000 (LWP 6218))]\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#1  0x00007fad69a17859 in abort () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#2  0x00007fad69a17729 in ?? () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#3  0x00007fad69a28fd6 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#4  0x00005652aac0a584 in fmatrix_tmult (A=..., f=1, B=..., C=...) at classifier_math.cu:111\n",
            "#5  0x00005652aac0a7c7 in main () at test.cu:13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGJ6uVNBVHUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d044452-1f0e-4e79-9173-a176dc01a260"
      },
      "source": [
        "!cuda-memcheck ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= CUDA-MEMCHECK\n",
            "========= This tool is deprecated and will be removed in a future release of the CUDA toolkit\n",
            "========= Please use the compute-sanitizer tool as a drop-in replacement\n",
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 6 rows.\n",
            "Allocated memory for inputs: 6 rows, 9 columns.\n",
            "Allocated memory for labels: 6 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t\n",
            "15\t19\t17\t14\t20\t29\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t\n",
            "1283\t1901\t174\t337\t326\t236\t\n",
            "1015\t1129\t333\t515\t624\t671\t\n",
            "472\t463\t117\t226\t262\t239\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.000000\n",
            "iter: 0, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 1, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 2, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 3, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 4, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 5, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 6, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 7, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 8, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 9, logloss: 0.000000, accuracy: 0.000000\n",
            "Duration (s): 0.000850\n",
            "final accuracy: 0.000000\n",
            "final weights: \n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Pk-JL7rAhi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "6WEXHyvpQ-1O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqs64V1tEysf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990f9f2f-03d7-4907-e6d9-a6a8ab7ffcfc"
      },
      "source": [
        "%%writefile test.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cu\"\n",
        "\n",
        "int main() {\n",
        "    // create a random matrix\n",
        "    fmatrix A = fmatrix_create_random_on_device(2,1);\n",
        "    fmatrix B = fmatrix_create_random_on_device(1,2);\n",
        "    fmatrix C = fmatrix_create_random_on_device(1,1);\n",
        "    printf(\"original matrix:\\n\");\n",
        "    fmatrix_device_print(B);\n",
        "    fmatrix_device_print(C);\n",
        "    // add the matrix to itself\n",
        "    fmatrix_tmult(A,1.0,B,C);\n",
        "    // print\n",
        "    printf(\"matrix result:\\n\");\n",
        "    fmatrix_device_print(A);\n",
        "    // free the memory\n",
        "    fmatrix_free_on_device(&A);\n",
        "    fmatrix_free_on_device(&B);\n",
        "    fmatrix_free_on_device(&C);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_35 -Wno-deprecated-gpu-targets -g -G -I cuda-samples/Common/ -L/usr/local/cuda/include test.cu fmatrix.cu cuda_stuff.cu"
      ],
      "metadata": {
        "id": "KsKCSpp4PoKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vErDd-FXQHdO",
        "outputId": "91acc7f9-ae3c-4343-c635-4e0685c1936c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original matrix:\n",
            "[\n",
            "0.480439,\t-0.123098\n",
            "]\n",
            "[\n",
            "0.480439\n",
            "]\n",
            "matrix result:\n",
            "[\n",
            "0.230821;\n",
            "-0.059141\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}