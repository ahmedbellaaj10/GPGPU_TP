{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cweMlOB0L4mG",
        "Po-TEvrWMJ_a"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedbellaaj10/GPGPU_TP/blob/main/Corr_Linear_classification_skeleton_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Author : Désiré OUEDRAOGO"
      ],
      "metadata": {
        "id": "g9qPct-D55eU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/NVIDIA/cuda-samples.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3ABSPkaBBHB",
        "outputId": "dfa1e79e-e2d3-444a-e975-75167500717f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 12395, done.\u001b[K\n",
            "remote: Counting objects: 100% (12395/12395), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1894/1894), done.\u001b[K\n",
            "remote: Total 12395 (delta 10520), reused 12332 (delta 10475), pack-reused 0\n",
            "Receiving objects: 100% (12395/12395), 130.30 MiB | 14.76 MiB/s, done.\n",
            "Resolving deltas: 100% (10520/10520), done.\n",
            "Updating files: 100% (3673/3673), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ewR7_sHJ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415d72f5-304b-40a0-b914-2385bdcbcee6"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Tue_Mar__8_18:18:20_PST_2022\n",
            "Cuda compilation tools, release 11.6, V11.6.124\n",
            "Build cuda_11.6.r11.6/compiler.31057947_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIyq5vPjxKc"
      },
      "source": [
        "Based on the lecture at https://sites.google.com/site/frehseg/teaching/ia307"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweMlOB0L4mG"
      },
      "source": [
        "# Provided Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lgwhE1N5_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efd06fa-da82-4d87-b130-eaeb26e71541"
      },
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        "\n",
        "//MACRO TO DEBUGG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "/** Error checking for use with CUDA Dynamic Parallelism */\n",
        "/*\n",
        "#define cdpErrchk(ans) { cdpAssert((ans), __FILE__, __LINE__); }\n",
        "__device__ void cdpAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      printf(\"GPU kernel assert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) assert(0);\n",
        "   }\n",
        "}\n",
        "*/\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivrxLaYOYPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a9a585-a11d-4371-aabc-e20c948dee40"
      },
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_stuff.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "## fmatrix Matrix Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A97U902HMog4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cfb20b-e041-44d8-a089-7fb890e7829e"
      },
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include \"cuda_stuff.cuh\" // for IDX2C\n",
        "\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    int cols;\n",
        "    int rows;\n",
        "} fmatrix;\n",
        "\n",
        "/* Access element (i,j) of matrix mat */\n",
        "#define getfm(mat,i,j) (mat.data[IDX2C(i,j,mat.rows)])\n",
        "\n",
        "\n",
        "int fmatrix_elements(fmatrix mat);\n",
        "int fmatrix_size(fmatrix mat);\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        "void fmatrix_assert(fmatrix mat);\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols);\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols);\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_host);\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host);\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "/** Create a matrix representing columns [a,b) of M.\n",
        " *  Note that the new matrix points into the\n",
        " *  data of M. The data is not copied to a new location.\n",
        " */\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host.\n",
        " *  If nb<0, print all rows.\n",
        " *\n",
        " * @attention: Works in device code if mat is on the device\n",
        " * and works in host code if mat is on the host.\n",
        " * All other cases require transferring the data first.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device.\n",
        " *  If nb<0, print all rows.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGwZ36ifWQ-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cb4e98-5087-4385-f954-d898c6200270"
      },
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "int fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "int fmatrix_size(fmatrix mat) {\n",
        "    // the following is only valid if matrix data already allocated,\n",
        "    // so it can't be used in create_on_... functions\n",
        "    // return fmatrix_elements(mat) * sizeof(mat.data[0]);\n",
        "    return fmatrix_elements(mat) * sizeof(float);\n",
        "}\n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat));\n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk(\n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat))\n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_device.data, mat_host.data,\n",
        "                   fmatrix_size(mat_host),\n",
        "                   cudaMemcpyHostToDevice\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,\n",
        "                   fmatrix_size(mat_device),\n",
        "                   cudaMemcpyDeviceToHost\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_device);\n",
        "    fmatrix mat_host = fmatrix_create_on_host(mat_device.rows, mat_device.cols);\n",
        "    fmatrix_data_to_host(mat_host,mat_device);\n",
        "    return mat_host;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix mat_device = fmatrix_create_on_device(mat_host.rows, mat_host.cols);\n",
        "    fmatrix_data_to_device(mat_host,mat_device);\n",
        "    return mat_device;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b) {\n",
        "    fmatrix_assert(M);\n",
        "    fmatrix A = {\n",
        "        .data = &getfm(M,0,a),\n",
        "        .cols = b-a,\n",
        "        .rows = M.rows\n",
        "    };\n",
        "    fmatrix_assert(A);\n",
        "    return A;\n",
        "}\n",
        "\n",
        "\n",
        "__host__\n",
        "__device__\n",
        "void fmatrix_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "   fmatrix_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing fmatrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKLTK8ELOdN"
      },
      "source": [
        "## Data I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD7rmOBmWfsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705c89f4-8481-4116-f7ea-d715abbfabbd"
      },
      "source": [
        "%%writefile read_csv.cuh\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef read_csv_H\n",
        "#define read_csv_H\n",
        "\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol);\n",
        "\n",
        "#endif"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing read_csv.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeedFsZ_WQx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308f9443-0c5a-4136-d074-d0881458c4bf"
      },
      "source": [
        "%%writefile read_csv.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"cuda_stuff.cuh\" // for matrix indexing\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for reading the dataset from a file\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Read a csv file with a given number of rows and columns */\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol) {\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  double ioTemp;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row_count = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "      // read the headers (and discard)\n",
        "\t\t\tgetline(infile, row_as_string, '\\n');\n",
        "      cout << \"headers: \" << row_as_string << \"!\" << std::endl;\n",
        "      for(int i = 0; i < nbrow; i++){\n",
        "  \t\t\tgetline(infile, row_as_string, '\\n');\n",
        "        // cout << \"read line \" << row_as_string << \"!\" << std::endl;\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "\t\t\t  for(int j = 0; j < nbcol; j++){\n",
        "          getline(line_stream, value, ',');\n",
        "\t\t\t\t\tioTemp = strtod(value.c_str(), NULL);\n",
        "          // cout << \"(\"<<i<<\",\"<<j<<\") = \"<< ioTemp << std::endl;\n",
        "\n",
        "\t\t\t\t\tdata_array[IDX2C(i,j,nbrow)] = ioTemp;\n",
        "\n",
        "\t\t\t\t}\n",
        "        ++row_count;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "    cout << \"Read \" << row_count << \" rows.\" << std::endl;\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing read_csv.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8ilQdYYroU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ebc74a-2761-4a91-be59-a7832214ccca"
      },
      "source": [
        "%%writefile preprocess_data.cuh\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef preprocess_data_H\n",
        "#define preprocess_data_H\n",
        "\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels );\n",
        "\n",
        "#endif"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocess_data.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaeUdw_KYaCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e06f3b0-97ff-4d96-fce9-18bdc0020422"
      },
      "source": [
        "%%writefile preprocess_data.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"preprocess_data.cuh\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   ld = number of rows\n",
        "   Example of use: a[IDX2C(0, 1, 50)] */\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for preprocessing the data set\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Split data into inputs and labels. Allocated memory for inputs and labels.\n",
        "   Since cuBLAS is column major, each input is in a column.\n",
        "   We also add 1.0 as first element to each input vector.\n",
        "*/\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels ) {\n",
        "    // The inputs are the first nbrows-1 columns.\n",
        "    // The labels are the last column (index nbrows-1), booleanized\n",
        "    // by the condition >= above_threshold\n",
        "    *input_array = (float *)malloc(nbrows * nb_inputs * sizeof(float));\n",
        "    *label_array = (float *)malloc(nbrows * nb_labels * sizeof(float));\n",
        "    //cout << &input_array << \" and \"<< &label_array << \" data \" << data_array << std::endl;\n",
        "    cout << \"Allocated memory for inputs: \" << nbrows << \" rows, \"<< nb_inputs << \" columns.\" << std::endl;\n",
        "    cout << \"Allocated memory for labels: \" << nbrows << \" rows, \"<< nb_labels << \" columns.\" << std::endl;\n",
        "\n",
        "    // Copy the data to X\n",
        "    for(int i = 0; i < nbrows; i++){\n",
        "      // Set the first element of each x to 1\n",
        "      (*input_array)[IDX2C(0,i,nb_inputs)] = 1.0;\n",
        "      // Copy the rest of x\n",
        "\t\t\tfor(int j = 1; j < nb_inputs; j++){\n",
        "\t\t\t\t(*input_array)[IDX2C(j,i,nb_inputs)] = data_array[IDX2C(i,j-1,nbrows)];\n",
        "\t\t\t}\n",
        "      float median_house_value = data_array[IDX2C(i,nbcols-1,nbrows)];\n",
        "      (*label_array)[IDX2C(0,i,nb_labels)] = 0.0;\n",
        "      (*label_array)[IDX2C(1,i,nb_labels)] = 0.0;\n",
        "      if (median_house_value >= above_threshold) {\n",
        "        (*label_array)[IDX2C(0,i,nb_labels)] = 1.0;\n",
        "      } else {\n",
        "        (*label_array)[IDX2C(1,i,nb_labels)] = 1.0;\n",
        "      }\n",
        "\t\t}\n",
        "\n",
        "    // Show some entries for double checking\n",
        "    cout << \"Inputs (first \"<<print_rows<<\"):\" << std::endl;\n",
        "\t  for(int j = 0; j < nb_inputs; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*input_array)[IDX2C(j,i,nb_inputs)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "    cout << \"Labels (first \"<<print_rows<<\"):\" << std::endl;\n",
        "    for(int j = 0; j < nb_labels; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*label_array)[IDX2C(j,i,nb_labels)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocess_data.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHy3EAid05oA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code That You Write"
      ],
      "metadata": {
        "id": "rR-9WFucUWLC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWS3hlAecOc"
      },
      "source": [
        "## Classifier Math"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_tmB-xbZKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c9927d-dfda-4aef-b9b2-52332e84b283"
      },
      "source": [
        "%%writefile classifier_math.cuh\n",
        "#ifndef classifier_math_H\n",
        "#define classifier_math_H\n",
        "\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "/** Returns a random float between min and max (including). */\n",
        "float float_rand( float min, float max );\n",
        "\n",
        "/** Initialize W with Xavier's method,\n",
        " *  scaled by a. */\n",
        "void xavier_weight_init(float a, fmatrix W);\n",
        "\n",
        "/** Compute the softmax for each column of Z and store in P **/\n",
        "void softmax_col(fmatrix P,fmatrix Z);\n",
        "\n",
        "///////////////////////////////////\n",
        "// TO BE COMPLETED\n",
        "// ... add your matrix math here\n",
        "///////////////////////////////////\n",
        "\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "void fmatrix_transpose(fmatrix Z, fmatrix Z_T);\n",
        "\n",
        "void fmatrix_add(fmatrix P,float a,fmatrix Y);\n",
        "\n",
        "void sigma_mu(fmatrix A, fmatrix mu, fmatrix sigma);\n",
        "\n",
        "void normalization(fmatrix A, fmatrix mu, fmatrix sigma);\n",
        "\n",
        "#endif"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing classifier_math.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgXwgv6Bbo-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa88626-cd13-4f33-a43b-2ecb9d5b448a"
      },
      "source": [
        "%%writefile classifier_math.cu\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Auxiliary function\n",
        "/////////////////////////////////////////////////////////\n",
        "// generate random numbers in interval [min,max]\n",
        "float float_rand( float min, float max )\n",
        "{\n",
        "    float scale = rand() / (float) RAND_MAX; /* [0, 1.0] */\n",
        "    return min + scale * ( max - min );      /* [min, max] */\n",
        "}\n",
        "\n",
        "void xavier_weight_init(float a, fmatrix W){\n",
        "    for (int j = 0; j < W.rows  ; ++j) {\n",
        "      for (int i = 0; i < W.cols  ; ++i) {\n",
        "          getfm(W,j,i) = a * (1.0/sqrt(W.cols+W.rows)) * float_rand(-1.0,1.0);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void stable_softmax_kernel(fmatrix P, fmatrix Z) {\n",
        "\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / Z.rows;\n",
        "    int i = idx % Z.rows;\n",
        "    if (i < Z.rows && j < Z.cols ){\n",
        "      //getfm(P,i,j) = getfm(Z,i,j);\n",
        "      float sum = 0;\n",
        "      float max = getfm(Z,0,j);\n",
        "      for (int k=0; k<Z.rows; k++){\n",
        "          if(getfm(Z,k,j) > max){\n",
        "            max = getfm(Z,k,j);\n",
        "            }\n",
        "      }\n",
        "        for (int k=0; k<Z.rows; k++){\n",
        "          sum += expf(getfm(Z,k,j) - max);\n",
        "      }\n",
        "      getfm(P,i,j) = expf(getfm(Z,i,j) - max) / sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_transpose_kernel(fmatrix Z, fmatrix Z_T) {\n",
        "\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / Z.rows;\n",
        "    int i = idx % Z.rows;\n",
        "\n",
        "    getfm(Z_T,j,i) = getfm(Z,i,j);\n",
        "\n",
        "    //int j = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    //int i = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "    //if (j < Z.rows && i < Z.cols )\n",
        "    /*for(int i=0; i<Z.cols; i++){\n",
        "      for(int j=0; j<Z.rows; j++){\n",
        "          getfm(Z_T,j,i) = getfm(Z,i,j);\n",
        "      }\n",
        "    }*/\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_add_kernel(fmatrix P,float a,fmatrix Y) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / P.rows;\n",
        "    int i = idx % P.rows;\n",
        "    if (i < P.rows && j < P.cols ){\n",
        "        getfm(P,i,j) += a*getfm(Y,i,j);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_multiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.cols; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,i,k)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void fmatrix_transpose(fmatrix Z, fmatrix Z_T) {\n",
        "\n",
        "    assert(Z.rows == Z_T.cols);\n",
        "    assert(Z.cols == Z_T.rows);\n",
        "\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(Z);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "\n",
        "    fmatrix_transpose_kernel<<< blocksPerGrid, threadsPerBlock >>>(Z, Z_T); // 1 thread pour la transposition\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "\n",
        "  }\n",
        "\n",
        "\n",
        "void softmax_col(fmatrix P,fmatrix Z) {\n",
        "    assert(P.cols==Z.cols);\n",
        "    assert(P.rows==Z.rows);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the softmax here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(Z);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    stable_softmax_kernel<<< blocksPerGrid, threadsPerBlock >>>(P,Z);\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    fmatrix_assert(A);\n",
        "    fmatrix_assert(B);\n",
        "    fmatrix_assert(C);\n",
        "    assert(A.rows == B.rows);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.cols == C.rows);\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "\n",
        "  }\n",
        "\n",
        "/** Compute P = P + a*Y */\n",
        "void fmatrix_add(fmatrix P,float a,fmatrix Y) {\n",
        "    fmatrix_assert(P);\n",
        "    fmatrix_assert(Y);\n",
        "    assert(P.rows == Y.rows);\n",
        "    assert(P.cols == Y.cols);\n",
        "    int threadsPerBlock = fmatrix_elements(P);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_add_kernel<<< blocksPerGrid, threadsPerBlock >>>(P,a,Y);\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "__global__\n",
        "void sigma_mu_kernel(fmatrix X, fmatrix mu, fmatrix sigma ) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / X.rows;\n",
        "    int i = idx % X.rows;\n",
        "    if (i < X.rows && j < X.cols ){\n",
        "      getfm(mu,i,0) = 0;\n",
        "      for (int k=0; k<X.cols; k++){\n",
        "          getfm(mu,i,0) += getfm(X,i,k);\n",
        "      }\n",
        "      getfm(mu,i,0) = getfm(mu,i,0) / (float) X.cols;\n",
        "\n",
        "      getfm(sigma,i,0) = 0;\n",
        "      for (int k=0; k<X.cols; k++){\n",
        "          getfm(sigma,i,0) += powf((getfm(X,i,k) - getfm(mu,i,0)), 2.0);\n",
        "      }\n",
        "      getfm(sigma,i,0) =  sqrtf(getfm(sigma,i,0) / (float) X.cols);\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__\n",
        "void normalization_kernel(fmatrix X, fmatrix mu, fmatrix sigma) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / X.rows;\n",
        "    int i = idx % X.rows;\n",
        "\n",
        "    if (i < X.rows && j < X.cols ){\n",
        "      if (getfm(sigma,i,0) != 0){\n",
        "      getfm(X,i,j) = (getfm(X,i,j) - getfm(mu,i,0))/getfm(sigma,i,0) ;\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute sigma mu (A) */\n",
        "void sigma_mu(fmatrix A, fmatrix mu, fmatrix sigma) {\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    sigma_mu_kernel<<< blocksPerGrid, threadsPerBlock >>>(A, mu, sigma);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "/* Compute normalization(A) */\n",
        "void normalization(fmatrix A, fmatrix mu, fmatrix sigma) {\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    normalization_kernel<<< blocksPerGrid, threadsPerBlock >>>(A, mu, sigma);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing classifier_math.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6G22rDKR3rv"
      },
      "source": [
        "## Evaluating Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7Vmzo72hpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b1a176-db3a-4a82-f335-6a8de9612bb6"
      },
      "source": [
        "%%writefile evaluate_accuracy.cuh\n",
        "\n",
        "/** Evaluate the accuracy of a linear classifier with D x M weight\n",
        " *  matrix W, using D x N input data X and M x N output labels Y.\n",
        " *  Z is a temporary matrix with dimensions M x N,\n",
        " *  which must be previously allocated.\n",
        " */\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z);\n",
        "\n",
        "/** Compute the logloss given M x N matrices of\n",
        " *  probabilities P and output labels Y\n",
        " *  and stores it in J.\n",
        " *  J is a matrix with dimensions 1 x 1,\n",
        " *  which must be previously allocated.\n",
        " *  logloss = sum_j -Y(j,k)*log(P(j,k))\n",
        " */\n",
        "void evaluate_logloss(fmatrix d_P,fmatrix d_Y,fmatrix d_J);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing evaluate_accuracy.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Z-9B4a2dwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a21e0df7-e1c4-4282-80f5-98f235babb98"
      },
      "source": [
        "%%writefile evaluate_accuracy.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__\n",
        "void evaluate_accuracy_kernel(fmatrix d_Y,fmatrix d_Z,int* count) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    if (idx < d_Z.cols){\n",
        "        float z_max = getfm(d_Z,0,idx);\n",
        "        int i_max = 0;\n",
        "        for (int i = 1; i < d_Z.rows; ++i) {\n",
        "          if (getfm(d_Z,i,idx)>z_max) {\n",
        "                z_max = getfm(d_Z,i,idx);\n",
        "                i_max = i;\n",
        "          }\n",
        "        }\n",
        "      if (getfm(d_Y,i_max,idx)>=0.5f) {\n",
        "          atomicAdd(count,1);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z) {\n",
        "    assert(d_Y.cols == d_Z.cols);\n",
        "    assert(d_Y.rows == d_Z.rows);\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 1. compute Z = W^T X\n",
        "  // --> each column of Z corresponds to one input\n",
        "  //////////////////////////////////////////\n",
        "  /*********************************\n",
        "  / TO BE COMPLETED\n",
        "  / ... compute Z = W^T X here ...\n",
        "  **********************************/\n",
        "  /* Compute d_Z = f*d_W^T*d_X */\n",
        "\n",
        "  fmatrix d_W_T = fmatrix_create_on_device(d_W.cols,d_W.rows);\n",
        "  fmatrix_transpose(d_W, d_W_T);\n",
        "  fmatrix_mult(d_Z, 1.0, d_W_T, d_X);\n",
        "  fmatrix_free_on_device(&d_W_T);\n",
        "\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 2. For each column z of Z,\n",
        "  // find argmax_k z_k\n",
        "  //////////////////////////////////////////\n",
        "\n",
        "\n",
        "  int true_class = 0;\n",
        "\n",
        "  int* d_count = 0;\n",
        "  gpuErrchk(cudaMalloc((void **)&d_count, sizeof(int)));\n",
        "  gpuErrchk(\n",
        "        cudaMemcpy( d_count, &true_class, sizeof(int), cudaMemcpyHostToDevice )\n",
        "  );\n",
        "\n",
        "    int threadsPerBlock = d_Z.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    evaluate_accuracy_kernel<<< blocksPerGrid, threadsPerBlock >>>(d_Y,d_Z,d_count);\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "  gpuErrchk(\n",
        "          cudaMemcpy(&true_class, d_count, sizeof(int), cudaMemcpyDeviceToHost )\n",
        "  );\n",
        "\n",
        "  //printf(\"Correct results: %d out of %d\\n\",true_class,nb_tested);\n",
        "  //printf(\"Accuracy: %f\\n\",(float)true_class/(float)nb_tested);\n",
        "  return (float)true_class/(float)d_Z.cols;\n",
        "}\n",
        "\n",
        "__global__\n",
        "void evaluate_logloss_kernel(fmatrix d_P,fmatrix d_Y, fmatrix d_J) {\n",
        "\n",
        "    getfm(d_J,0,0) = 0.0;\n",
        "    float temp = 0.0;\n",
        "    for(int k=0; k<d_Y.cols ; k++)\n",
        "      {\n",
        "        for(int j=0; j<d_Y.rows; j++){\n",
        "          if(getfm(d_Y,j,k) > 0.0 && getfm(d_P,j,k) > 0.0){\n",
        "            temp = -getfm(d_Y,j,k)*logf(getfm(d_P,j,k));\n",
        "            getfm(d_J,0,0) += temp;\n",
        "          }\n",
        "\n",
        "\n",
        "      }\n",
        "    }\n",
        "\n",
        "    getfm(d_J,0,0) *= 1.0 / d_Y.cols;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "void evaluate_logloss(fmatrix d_P,fmatrix d_Y,fmatrix d_J) {\n",
        "    assert(d_Y.cols == d_P.cols);\n",
        "    assert(d_Y.rows == d_P.rows);\n",
        "    fmatrix_assert(d_Y);\n",
        "    fmatrix_assert(d_P);\n",
        "\n",
        "\n",
        "    //float J = 0.0;\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the logloss here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "    evaluate_logloss_kernel<<< 1, 1 >>>(d_P, d_Y, d_J);\n",
        "\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "    //return J;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate_accuracy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AwZh8WULi_F"
      },
      "source": [
        "## Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWO5p1NeHE9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c35d057-8909-4fb1-ddaf-d3da2afed59c"
      },
      "source": [
        "%%writefile linear_classification.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"preprocess_data.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"evaluate_accuracy.cuh\"\n",
        "/* Includes, cuda */\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "/////////////////////////////////////////////////////////\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    size_t N_train = 12000; //12000; // points for training (Google: 12000)\n",
        "    size_t N_test = 5000; // 5000; // points for validation (Google: 5000)\n",
        "    size_t N = N_train;\n",
        "    size_t Nall = N_train+N_test;\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Reading the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    fmatrix alldata = fmatrix_create_on_host(Nall,data_columns);\n",
        "    read_csv(\"sample_data/california_housing_train.csv\",alldata.data,Nall,data_columns);\n",
        "    //fmatrix_print(alldata);\n",
        "\n",
        "    size_t D = data_columns-1+1; // remove output column, add column with const. 1.0\n",
        "    size_t M = 2; // number of labels (one-hot encoding)\n",
        "    fmatrix Xall = fmatrix_create_on_host(D,Nall);\n",
        "    fmatrix Yall = fmatrix_create_on_host(M,Nall);\n",
        "    get_inputs_and_labels(alldata.data,&Xall.data,&Yall.data,Nall,data_columns,D,M);\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Inputs and labels are now available in X and Y.\n",
        "    // Each input is a column in X; X is of dimension D x N\n",
        "    // each label is a column in Y; Y is of dimension M x N\n",
        "    /////////////////////////////////////////////////////////\n",
        "\n",
        "    // Logfile\n",
        "    FILE* fp = fopen(\"log.txt\", \"w\");\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for Stochastic Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    int nb_iter = 40;           // defeault: 10;\n",
        "    int periods = nb_iter;      // reporting period\n",
        "    int batch_size = N;         // defeault: N;\n",
        "    float learning_rate = 0.0001; // default: 1e-7\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Memory Allocation and Initialization\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // take X,Y to be the first N columns of all data\n",
        "    fmatrix h_X = fmatrix_subcolumns(Xall,0,N);\n",
        "    fmatrix h_Y = fmatrix_subcolumns(Yall,0,N);\n",
        "    fmatrix h_Xtest = fmatrix_subcolumns(Xall,N,Nall);\n",
        "    fmatrix h_Ytest = fmatrix_subcolumns(Yall,N,Nall);\n",
        "    fmatrix h_W = fmatrix_create_on_host(D,M);\n",
        "    fmatrix h_J = fmatrix_create_on_host(1,1);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Initializing Weight Matrix\n",
        "    // its dimension is D x M\n",
        "    /////////////////////////////////////////////////////////\n",
        "    xavier_weight_init(1.0,h_W);\n",
        "\n",
        "    //////////////////////////////\n",
        "    // Copy data to device      //\n",
        "    //////////////////////////////\n",
        "    fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "    fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "    fmatrix d_Xtest = fmatrix_copy_to_device(h_Xtest);\n",
        "    fmatrix d_Ytest = fmatrix_copy_to_device(h_Ytest);\n",
        "    fmatrix d_W = fmatrix_copy_to_device(h_W);\n",
        "    fmatrix d_J = fmatrix_copy_to_device(h_J);\n",
        "\n",
        "    /////////////////////////////////////////\n",
        "    // Create auxiliary matrices on device //\n",
        "    /////////////////////////////////////////\n",
        "    fmatrix d_Z = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_P = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_G = fmatrix_create_on_device(D,M);\n",
        "    // auxiliary matrix for computing Z=W^T X on test data\n",
        "    fmatrix d_Ztest = fmatrix_create_on_device(M,d_Xtest.cols);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Batch Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    //fmatrix_device_print(d_X);\n",
        "    //fmatrix_device_print(d_W);\n",
        "\n",
        "    fmatrix mu = fmatrix_create_on_device(d_X.rows,1);\n",
        "    fmatrix sigma = fmatrix_create_on_device(d_X.rows,1);\n",
        "    sigma_mu(d_X, mu, sigma);\n",
        "    normalization(d_X, mu, sigma);\n",
        "\n",
        "    fmatrix mu_test = fmatrix_create_on_device(d_X.rows,1);\n",
        "    fmatrix sigma_test = fmatrix_create_on_device(d_X.rows,1);\n",
        "    sigma_mu(d_Xtest, mu_test, sigma_test);\n",
        "    normalization(d_Xtest, mu_test, sigma_test);\n",
        "\n",
        "     /* Evaluate the accuracy */\n",
        "    float accuracy = 0;\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"initial accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    float J = 0;\n",
        "\n",
        "    clock_t tstart_total, tend;\n",
        "    tstart_total = clock();\n",
        "\n",
        "    //int batch_pointer = 0;\n",
        "\n",
        "    for (int i=0; i<nb_iter; ++i){\n",
        "                ////////////////////////////////\n",
        "                // compute Z = W^T X\n",
        "                // --> each column z of Z corresponds to one column x of X\n",
        "                ////////////////////////////////\n",
        "\n",
        "                ///////////////////////////////////\n",
        "                // TO BE COMPLETED\n",
        "                ///////////////////////////////////\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                fmatrix d_W_T = fmatrix_create_on_device(d_W.cols,d_W.rows);\n",
        "                fmatrix_transpose(d_W, d_W_T);\n",
        "\n",
        "                fmatrix_mult(d_Z, 1.0, d_W_T, d_X);\n",
        "                fmatrix_free_on_device(&d_W_T);\n",
        "\n",
        "                ////////////////////////////////\n",
        "                // For each column z of Z, compute activation p(z);\n",
        "                // then update W\n",
        "                ////////////////////////////////\n",
        "\n",
        "                // compute softmax per column of Z and store in Z\n",
        "                //fmatrix_device_print(d_Z);\n",
        "                softmax_col(d_P,d_Z);\n",
        "                //fmatrix_device_print(d_P);\n",
        "\n",
        "                ///////////////////////////////////\n",
        "                // TO BE COMPLETED\n",
        "                ///////////////////////////////////\n",
        "\n",
        "                // evaluate logloss (for reporting only)\n",
        "\n",
        "                evaluate_logloss(d_P, d_Y, d_J);\n",
        "                fmatrix_data_to_host(h_J,d_J);\n",
        "                J = getfm(h_J,0,0);\n",
        "\n",
        "\n",
        "                ///////////////////////////////////\n",
        "                // TO BE COMPLETED\n",
        "                ///////////////////////////////////\n",
        "\n",
        "                // Q:=P-Y\n",
        "                // compute gradient G = XQ^T\n",
        "                // ... possibly work with G here ...\n",
        "                // update weights W = W - learning_rate*G\n",
        "\n",
        "                ///////////////////////////////////\n",
        "                // TO BE COMPLETED\n",
        "                ///////////////////////////////////\n",
        "\n",
        "                fmatrix h_Q = fmatrix_create_on_host(M,batch_size);\n",
        "                fmatrix d_Q = fmatrix_create_on_device(M,batch_size);\n",
        "                fmatrix d_Q_T = fmatrix_create_on_device(batch_size,M);\n",
        "\n",
        "                for(int l=0; l<M; l++){\n",
        "                  for(int j=0; j<batch_size; j++){\n",
        "                    getfm(h_Q,l,j) = 0.0;\n",
        "                  }\n",
        "                }\n",
        "\n",
        "                fmatrix_data_to_device(h_Q, d_Q);\n",
        "\n",
        "                fmatrix_add(d_Q, 1.0, d_P);\n",
        "                fmatrix_add(d_Q, -1.0, d_Y);\n",
        "\n",
        "                fmatrix_transpose(d_Q, d_Q_T);\n",
        "                fmatrix_mult(d_G, 1.0, d_X, d_Q_T);\n",
        "\n",
        "                //fmatrix_device_print(d_G);\n",
        "\n",
        "                fmatrix_add(d_W, -learning_rate, d_G);\n",
        "\n",
        "                //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "\n",
        "                ////////////////////////////////\n",
        "                // For reporting, compute logloss and accuracy\n",
        "                ////////////////////////////////\n",
        "                if (i%(nb_iter/periods)==0) {\n",
        "                  float accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "                  printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
        "                  fprintf(fp, \"%f,%f\\n\", J, accuracy);\n",
        "                }\n",
        "\n",
        "    }\n",
        "    tend = clock();\n",
        "    float duration = ((float)(tend-tstart_total))/CLOCKS_PER_SEC;\n",
        "    printf(\"Duration (s): %f\\n\",duration);\n",
        "    /* Evaluate the accuracy */\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"final accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    printf(\"final weights: \\n\");\n",
        "    fmatrix_device_print(d_W);\n",
        "\n",
        "    /* Memory clean up */\n",
        "    /** No need to free h_X, h_Y, h_Xtest, h_Ytest since\n",
        "     *  they all point to Xall\n",
        "     */\n",
        "    fmatrix_free_on_host(&h_W);\n",
        "    fmatrix_free_on_host(&Xall);\n",
        "    fmatrix_free_on_host(&Yall);\n",
        "\n",
        "    fmatrix_free_on_device(&d_X);\n",
        "    fmatrix_free_on_device(&d_Y);\n",
        "    fmatrix_free_on_device(&d_Xtest);\n",
        "    fmatrix_free_on_device(&d_Ytest);\n",
        "    fmatrix_free_on_device(&d_W);\n",
        "    fmatrix_free_on_device(&d_Z);\n",
        "    fmatrix_free_on_device(&d_J);\n",
        "\n",
        "    // Close log file\n",
        "    fclose(fp);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting linear_classification.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrATC8s9LsDw"
      },
      "source": [
        "# Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z52xd0NMRKXb"
      },
      "source": [
        "!nvcc -arch=sm_35 -Wno-deprecated-gpu-targets -I /content/cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZVqTfXcLvPr"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV_vFkIT7fV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a1cc61-9f07-4984-f161-7f38769b5db2"
      },
      "source": [
        "%%time\n",
        "!./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 17000 rows.\n",
            "Allocated memory for inputs: 17000 rows, 9 columns.\n",
            "Allocated memory for labels: 17000 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t-114.58\t-114.59\t-114.59\t-114.6\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t33.61\t34.83\t33.61\t34.83\t\n",
            "15\t19\t17\t14\t20\t29\t25\t41\t34\t46\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t2907\t812\t4789\t1497\t\n",
            "1283\t1901\t174\t337\t326\t236\t680\t168\t1175\t309\t\n",
            "1015\t1129\t333\t515\t624\t671\t1841\t375\t3134\t787\t\n",
            "472\t463\t117\t226\t262\t239\t633\t158\t1056\t271\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t2.6768\t1.7083\t2.1782\t2.1908\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.297000\n",
            "iter: 0, logloss: 0.880316, accuracy: 0.720400\n",
            "iter: 1, logloss: 0.504255, accuracy: 0.751000\n",
            "iter: 2, logloss: 0.422960, accuracy: 0.761200\n",
            "iter: 3, logloss: 0.386904, accuracy: 0.757200\n",
            "iter: 4, logloss: 0.369305, accuracy: 0.764400\n",
            "iter: 5, logloss: 0.358382, accuracy: 0.765400\n",
            "iter: 6, logloss: 0.350840, accuracy: 0.769800\n",
            "iter: 7, logloss: 0.345344, accuracy: 0.771600\n",
            "iter: 8, logloss: 0.340893, accuracy: 0.775600\n",
            "iter: 9, logloss: 0.337255, accuracy: 0.777600\n",
            "iter: 10, logloss: 0.334166, accuracy: 0.778800\n",
            "iter: 11, logloss: 0.331464, accuracy: 0.781000\n",
            "iter: 12, logloss: 0.329016, accuracy: 0.783200\n",
            "iter: 13, logloss: 0.326829, accuracy: 0.784800\n",
            "iter: 14, logloss: 0.324880, accuracy: 0.785800\n",
            "iter: 15, logloss: 0.323087, accuracy: 0.788000\n",
            "iter: 16, logloss: 0.321419, accuracy: 0.789400\n",
            "iter: 17, logloss: 0.319857, accuracy: 0.791800\n",
            "iter: 18, logloss: 0.318399, accuracy: 0.793400\n",
            "iter: 19, logloss: 0.317045, accuracy: 0.794800\n",
            "iter: 20, logloss: 0.315766, accuracy: 0.796600\n",
            "iter: 21, logloss: 0.314556, accuracy: 0.797200\n",
            "iter: 22, logloss: 0.313411, accuracy: 0.799000\n",
            "iter: 23, logloss: 0.312324, accuracy: 0.799400\n",
            "iter: 24, logloss: 0.311290, accuracy: 0.799000\n",
            "iter: 25, logloss: 0.310308, accuracy: 0.800000\n",
            "iter: 26, logloss: 0.309370, accuracy: 0.799600\n",
            "iter: 27, logloss: 0.308470, accuracy: 0.799800\n",
            "iter: 28, logloss: 0.307620, accuracy: 0.801000\n",
            "iter: 29, logloss: 0.306804, accuracy: 0.801600\n",
            "iter: 30, logloss: 0.306025, accuracy: 0.803200\n",
            "iter: 31, logloss: 0.305280, accuracy: 0.804000\n",
            "iter: 32, logloss: 0.304565, accuracy: 0.804800\n",
            "iter: 33, logloss: 0.303880, accuracy: 0.805400\n",
            "iter: 34, logloss: 0.303225, accuracy: 0.805600\n",
            "iter: 35, logloss: 0.302596, accuracy: 0.806400\n",
            "iter: 36, logloss: 0.301994, accuracy: 0.807600\n",
            "iter: 37, logloss: 0.301416, accuracy: 0.807600\n",
            "iter: 38, logloss: 0.300859, accuracy: 0.808200\n",
            "iter: 39, logloss: 0.300325, accuracy: 0.808600\n",
            "Duration (s): 0.310331\n",
            "final accuracy: 0.808600\n",
            "final weights: \n",
            "[\n",
            "-0.953477,\t1.002265;\n",
            "-0.268989,\t0.433337;\n",
            "-0.500534,\t0.634097;\n",
            "0.297692,\t-0.160771;\n",
            "-0.088475,\t-0.097220;\n",
            "0.315745,\t-0.344545;\n",
            "-0.701702,\t0.614425;\n",
            "0.606749,\t-0.114697;\n",
            "0.998815,\t-0.758321\n",
            "]\n",
            "CPU times: user 29.2 ms, sys: 6.55 ms, total: 35.7 ms\n",
            "Wall time: 1.44 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIyxh0ClrIz"
      },
      "source": [
        "Let's plot the logloss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR2kCNEIlpqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "d806023b-fd08-4be8-adc4-79dc6cdce215"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('log.txt',sep=',',header=None)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data[0],label=\"logloss\")\n",
        "plt.legend()\n",
        "ax2=ax.twinx()\n",
        "ax2.plot([], [])\n",
        "ax2.plot(data[1],label=\"accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss = 0.300344 \\\n",
        "accuracy =  0.808200 \\\n",
        "hyperparameters : \\\n",
        "learning rate = 1e-4 \\\n",
        "nb_epochs = 40 \\\n",
        "batch_size = 12000"
      ],
      "metadata": {
        "id": "zYR3dk4IECcm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aUKkNJqTDZ"
      },
      "source": [
        "# Debugging\n",
        "Compile with debugging info on the host (`-g`) and device (`-G`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcfLGo1UrMq9"
      },
      "source": [
        "!nvcc -g -G -I /content/cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuaGO10rRm9"
      },
      "source": [
        "Run the debugger cuda-gdb, stopping at the first error that is detected. Shows first the call stack on the GPU, the values of local variables, then the call stack on the host (thread 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ8nAtzGTRgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ed3127-1cab-422a-ee19-bffaee2f32bf"
      },
      "source": [
        "! printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "! cat tmp.txt\n",
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set cuda memcheck on\n",
            "set cuda api_failures stop\n",
            "catch throw\n",
            "r\n",
            "bt\n",
            "info locals\n",
            "thread 1\n",
            "bt\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 6 rows.\n",
            "Allocated memory for inputs: 6 rows, 9 columns.\n",
            "Allocated memory for labels: 6 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t\n",
            "15\t19\t17\t14\t20\t29\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t\n",
            "1283\t1901\t174\t337\t326\t236\t\n",
            "1015\t1129\t333\t515\t624\t671\t\n",
            "472\t463\t117\t226\t262\t239\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[Detaching after fork from child process 3865]\n",
            "[New Thread 0x7f3b230b1000 (LWP 3873)]\n",
            "[New Thread 0x7f3b228b0000 (LWP 3874)]\n",
            "initial accuracy: 0.500000\n",
            "iter: 0, logloss: 3.363147, accuracy: 0.500000\n",
            "iter: 1, logloss: 3.363146, accuracy: 0.500000\n",
            "iter: 2, logloss: 3.363145, accuracy: 0.500000\n",
            "iter: 3, logloss: 3.363144, accuracy: 0.500000\n",
            "iter: 4, logloss: 3.363143, accuracy: 0.500000\n",
            "iter: 5, logloss: 3.363142, accuracy: 0.500000\n",
            "iter: 6, logloss: 3.363141, accuracy: 0.500000\n",
            "iter: 7, logloss: 3.363140, accuracy: 0.500000\n",
            "iter: 8, logloss: 3.363139, accuracy: 0.500000\n",
            "iter: 9, logloss: 3.363138, accuracy: 0.500000\n",
            "Duration (s): 3.248129\n",
            "final accuracy: 0.500000\n",
            "final weights: \n",
            "[\n",
            "0.205139,\t-0.063687;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161748;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "[Thread 0x7f3b230b1000 (LWP 3873) exited]\n",
            "[Thread 0x7f3b2a9b1000 (LWP 3860) exited]\n",
            "[Inferior 1 (process 3860) exited normally]\n",
            "tmp.txt:5: Error in sourced command file:\n",
            "No stack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGJ6uVNBVHUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4299e8-aab2-4995-aec9-bdd2fbbd9074"
      },
      "source": [
        "!cuda-memcheck ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= CUDA-MEMCHECK\n",
            "========= This tool is deprecated and will be removed in a future release of the CUDA toolkit\n",
            "========= Please use the compute-sanitizer tool as a drop-in replacement\n",
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 6 rows.\n",
            "Allocated memory for inputs: 6 rows, 9 columns.\n",
            "Allocated memory for labels: 6 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t\n",
            "15\t19\t17\t14\t20\t29\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t\n",
            "1283\t1901\t174\t337\t326\t236\t\n",
            "1015\t1129\t333\t515\t624\t671\t\n",
            "472\t463\t117\t226\t262\t239\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "initial accuracy: 1.000000\n",
            "[\n",
            "1.000000,\t1.000000,\t1.000000,\t1.000000;\n",
            "-114.309998,\t-114.470001,\t-114.559998,\t-114.570000;\n",
            "34.189999,\t34.400002,\t33.689999,\t33.639999;\n",
            "15.000000,\t19.000000,\t17.000000,\t14.000000;\n",
            "5612.000000,\t7650.000000,\t720.000000,\t1501.000000;\n",
            "1283.000000,\t1901.000000,\t174.000000,\t337.000000;\n",
            "1015.000000,\t1129.000000,\t333.000000,\t515.000000;\n",
            "472.000000,\t463.000000,\t117.000000,\t226.000000;\n",
            "1.493600,\t1.820000,\t1.650900,\t3.191700\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606690,\t0.071937,\t-0.791307,\t-0.887247;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 0, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606690,\t0.071937,\t-0.791307,\t-0.887247;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 1, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 2, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 3, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 4, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 5, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 6, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 7, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 8, logloss: 0.000000, accuracy: 0.000000\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "[\n",
            "nan,\tnan,\tnan,\tnan;\n",
            "1.606672,\t0.071919,\t-0.791325,\t-0.887265;\n",
            "0.647916,\t1.295843,\t-0.894747,\t-1.049011;\n",
            "-0.650945,\t1.432078,\t0.390567,\t-1.171700;\n",
            "0.607537,\t1.318614,\t-1.099324,\t-0.826827;\n",
            "0.509270,\t1.385342,\t-1.062840,\t-0.831772;\n",
            "0.802337,\t1.144908,\t-1.247079,\t-0.700167;\n",
            "0.996940,\t0.938104,\t-1.323805,\t-0.611238;\n",
            "-0.807573,\t-0.324317,\t-0.574681,\t1.706571\n",
            "]\n",
            "iter: 9, logloss: 0.000000, accuracy: 0.000000\n",
            "Duration (s): 0.412770\n",
            "final accuracy: 0.000000\n",
            "final weights: \n",
            "[\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan;\n",
            "nan,\tnan\n",
            "]\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Pk-JL7rAhi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqs64V1tEysf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}