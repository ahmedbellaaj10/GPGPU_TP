{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedbellaaj10/GPGPU_TP/blob/main/linear_classification_2021_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd38XvZK2sy"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ewR7_sHJ00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969e3376-c55d-4906-9554-f754b0161b10"
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download repository with helper_cuda.h:"
      ],
      "metadata": {
        "id": "neVqpQNceYFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ase9AQyweUSJ",
        "outputId": "72a98391-3cbd-45f3-a0bd-d3e68b9a368e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 18274, done.\u001b[K\n",
            "remote: Counting objects: 100% (3689/3689), done.\u001b[K\n",
            "remote: Compressing objects: 100% (576/576), done.\u001b[K\n",
            "remote: Total 18274 (delta 3346), reused 3150 (delta 3113), pack-reused 14585\u001b[K\n",
            "Receiving objects: 100% (18274/18274), 133.19 MiB | 12.27 MiB/s, done.\n",
            "Resolving deltas: 100% (16006/16006), done.\n",
            "Updating files: 100% (3998/3998), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIyq5vPjxKc"
      },
      "source": [
        "Based on the lecture at https://sites.google.com/site/frehseg/teaching/ia307"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cweMlOB0L4mG"
      },
      "source": [
        "# Provided Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-TEvrWMJ_a"
      },
      "source": [
        "## CUDA Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-lgwhE1N5_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6fa322-12b5-4062-f9c4-ccad86fed896"
      },
      "source": [
        "%%writefile cuda_stuff.cuh\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#ifndef cuda_stuff_H\n",
        "#define cuda_stuff_H\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   nb_rows = number of rows */\n",
        "#define IDX2C(i,j,nb_rows) (((j)*(nb_rows))+(i))\n",
        "\n",
        "//MACRO TO DEBUGG CUDA FUNCTIONS\n",
        "/** Error checking,\n",
        " *  taken from https://stackoverflow.com/questions/14038589/what-is-the-canonical-way-to-check-for-errors-using-the-cuda-runtime-api\n",
        " */\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "/** Error checking for use with CUDA Dynamic Parallelism */\n",
        "/*\n",
        "#define cdpErrchk(ans) { cdpAssert((ans), __FILE__, __LINE__); }\n",
        "__device__ void cdpAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      printf(\"GPU kernel assert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) assert(0);\n",
        "   }\n",
        "}\n",
        "*/\n",
        "void device_synchronize();\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_stuff.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iivrxLaYOYPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dfee00f-fa0f-4c45-8795-0c45490220a7"
      },
      "source": [
        "%%writefile cuda_stuff.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "\n",
        "void device_synchronize(){\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "}"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cuda_stuff.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fsEMpauK8lW"
      },
      "source": [
        "## fmatrix Matrix Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A97U902HMog4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4a035f-00c1-4057-e827-b2901e287961"
      },
      "source": [
        "%%writefile fmatrix.cuh\n",
        "#ifndef fmatrices_H\n",
        "#define fmatrices_H\n",
        "#include \"cuda_stuff.cuh\" // for IDX2C\n",
        "\n",
        "////////////////////////////////////////\n",
        "// basic data structure and access macro\n",
        "////////////////////////////////////////\n",
        "typedef struct {\n",
        "    float* data;\n",
        "    int cols;\n",
        "    int rows;\n",
        "} fmatrix;\n",
        "\n",
        "/** Access element (i,j) of matrix M\n",
        " *\n",
        " *  Usage example:\n",
        " *  For computing A = B^T + C), loop over i and j with:\n",
        " *    getfm(A,i,j) = getfm(B,j,i) + getfm(C,i,j);\n",
        " **/\n",
        "#define getfm(M,i,j) (M.data[IDX2C(i,j,M.rows)])\n",
        "\n",
        "////////////////////////////////////////\n",
        "// utility functions\n",
        "////////////////////////////////////////\n",
        "/** Returns the number of elements in the matrix.\n",
        " *\n",
        " *  Useful for computing, e.g., the size\n",
        " *  of a 1D-vector that contains the same numbers.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_elements(fmatrix mat);\n",
        "\n",
        "/** Returns the memory occupied by the matrix elements in bytes\n",
        " *  (not including the variables in the struct mat).\n",
        " *\n",
        " *  Useful for allocating memory for the data.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "int fmatrix_size(fmatrix mat);\n",
        "\n",
        "/** Assert that the matrix is coherent: all fields nonzero. */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_assert(fmatrix mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Create, copy, destroy\n",
        "////////////////////////////////////////\n",
        "/** Allocate memory on host */\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols);\n",
        "\n",
        "/** Allocate memory on device */\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols);\n",
        "\n",
        "/** Create a matrix representing columns [a,b) of M.\n",
        " *  Note that the new matrix uses a pointer to the\n",
        " *  data of M. The data is not copied to a new location.\n",
        " *  If M is destroyed, this matrix is useless.\n",
        " */\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b);\n",
        "\n",
        "/** Copy data from matrix on device to host\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy data from matrix on host to device\n",
        " *  (no memory allocation). */\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from device to host, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device);\n",
        "\n",
        "/** Copy matrix from host to device, allocating new memory. */\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host);\n",
        "\n",
        "/** Free data memory on host.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_host(fmatrix* mat);\n",
        "\n",
        "/** Free data memory on device.\n",
        " *  This zeros out the data pointer of the fmatrix struct,\n",
        " *  so a pointer is required. */\n",
        "void fmatrix_free_on_device(fmatrix* mat);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Input and Output\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the host.\n",
        " *  If nb<0, print all rows.\n",
        " */\n",
        " __host__\n",
        " __device__\n",
        "void fmatrix_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print the first nb rows of the matrix mat\n",
        " *  on the device.\n",
        " *  If nb<0, print all rows.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_print(fmatrix mat, int nb=-1);\n",
        "\n",
        "/** Print a matrix to a csv file.\n",
        " *\n",
        " *  This version copies the matrix to host first.\n",
        " */\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat);\n",
        "\n",
        "/** Read a matrix from a csv file.\n",
        " *\n",
        " *  This version creates the matrix on the host first.\n",
        " */\n",
        "fmatrix fmatrix_device_from_csv(const char* filename);\n",
        "\n",
        "////////////////////////////////////////\n",
        "// Useful\n",
        "////////////////////////////////////////\n",
        "\n",
        "/** Create a matrix with random values between -1 and 1\n",
        " *  on the device */\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols);\n",
        "\n",
        "#endif\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGwZ36ifWQ-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93690aee-53a7-4aca-b567-ce46c39b0acb"
      },
      "source": [
        "%%writefile fmatrix.cu\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "// for reading CSV files, we use some C++\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "\n",
        "int fmatrix_elements(fmatrix mat) {\n",
        "     return mat.cols*mat.rows;\n",
        "}\n",
        "\n",
        "int fmatrix_size(fmatrix mat) {\n",
        "//    fmatrix_assert(mat);\n",
        "     return fmatrix_elements(mat) * sizeof(float);\n",
        "}\n",
        "\n",
        "void fmatrix_assert(fmatrix mat) {\n",
        "    assert(mat.data);\n",
        "    assert(mat.cols);\n",
        "    assert(mat.rows);\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_host(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    mat.data = (float*)malloc(fmatrix_size(mat));\n",
        "    assert(mat.data);\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_on_device(int rows, int cols) {\n",
        "    assert(cols>0);\n",
        "    assert(rows>0);\n",
        "    fmatrix mat;\n",
        "    mat.cols = cols;\n",
        "    mat.rows = rows;\n",
        "    gpuErrchk(\n",
        "        cudaMalloc((void **)&(mat.data), fmatrix_size(mat))\n",
        "    );\n",
        "    return mat;\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_device(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_device.data, mat_host.data,\n",
        "                   fmatrix_size(mat_host),\n",
        "                   cudaMemcpyHostToDevice\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "void fmatrix_data_to_host(fmatrix mat_host, fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix_assert(mat_device);\n",
        "    assert(mat_host.cols==mat_device.cols);\n",
        "    assert(mat_host.rows==mat_device.rows);\n",
        "    gpuErrchk(\n",
        "        cudaMemcpy( mat_host.data, mat_device.data,\n",
        "                   fmatrix_size(mat_device),\n",
        "                   cudaMemcpyDeviceToHost\n",
        "                   )\n",
        "        );\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_host(fmatrix mat_device) {\n",
        "    fmatrix_assert(mat_device);\n",
        "    fmatrix mat_host = fmatrix_create_on_host(mat_device.rows, mat_device.cols);\n",
        "    fmatrix_data_to_host(mat_host,mat_device);\n",
        "    return mat_host;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_copy_to_device(fmatrix mat_host) {\n",
        "    fmatrix_assert(mat_host);\n",
        "    fmatrix mat_device = fmatrix_create_on_device(mat_host.rows, mat_host.cols);\n",
        "    fmatrix_data_to_device(mat_host,mat_device);\n",
        "    return mat_device;\n",
        "}\n",
        "\n",
        "/** We could do it like this, but it would not set our pointer M.data to 0.\n",
        "... fmatrix_free_on_host(M)\n",
        "void fmatrix_free_on_host(fmatrix mat) {\n",
        "    fmatrix_assert(mat);\n",
        "  free(mat.data);\n",
        "  mat.data = 0;\n",
        "  mat.cols = 0;\n",
        "  mat.rows = 0;\n",
        "}\n",
        "*/\n",
        "\n",
        "void fmatrix_free_on_host(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  free(mat->data);\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "void fmatrix_free_on_device(fmatrix* mat) {\n",
        "    fmatrix_assert(*mat);\n",
        "  gpuErrchk(cudaFree(mat->data));\n",
        "  mat->data = 0;\n",
        "  mat->cols = 0;\n",
        "  mat->rows = 0;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_subcolumns(fmatrix M, int a, int b) {\n",
        "    fmatrix_assert(M);\n",
        "    fmatrix A = {\n",
        "        .data = &getfm(M,0,a),\n",
        "        .cols = b-a,\n",
        "        .rows = M.rows\n",
        "    };\n",
        "    fmatrix_assert(A);\n",
        "    return A;\n",
        "}\n",
        "\n",
        "\n",
        "__host__\n",
        "__device__\n",
        "void fmatrix_print(fmatrix mat, int nb){\n",
        "    if (nb<0 || nb > mat.rows) {\n",
        "        nb = mat.rows;\n",
        "    }\n",
        "    printf(\"[\\n\");\n",
        "    for (int i = 0 ; i < nb; i++){\n",
        "      for (int j = 0 ; j<mat.cols; j++){\n",
        "        printf(\"%f\", getfm(mat,i,j));\n",
        "        if (j+1<mat.cols) {\n",
        "          printf(\",\\t\");\n",
        "        }\n",
        "      }\n",
        "      if (i+1<nb) {\n",
        "        printf(\";\\n\");\n",
        "      }\n",
        "    }\n",
        "    if (nb < mat.rows) {\n",
        "      printf(\"\\n...\\n\");\n",
        "    }\n",
        "  printf(\"\\n]\\n\");\n",
        "}\n",
        "\n",
        "void fmatrix_device_print(fmatrix mat, int nb){\n",
        "   // allocate copy\n",
        "   fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "   fmatrix_print(tmp,nb);\n",
        "   fmatrix_free_on_host(&tmp);\n",
        "}\n",
        "\n",
        "void fmatrix_device_to_csv(const char* filename, fmatrix mat) {\n",
        "  // Open file\n",
        "  FILE* fp = fopen(filename, \"w\");\n",
        "  // allocate copy\n",
        "  fmatrix tmp = fmatrix_copy_to_host(mat);\n",
        "  for (int i = 0 ; i < tmp.rows; i++){\n",
        "    for (int j = 0 ; j<tmp.cols; j++){\n",
        "      // Note: %.15g gives 15 significant digits (full double precision)\n",
        "      fprintf(fp,\"%.15g\", getfm(tmp,i,j));\n",
        "      if (j+1<tmp.cols) {\n",
        "        fprintf(fp,\",\");\n",
        "      }\n",
        "    }\n",
        "    fprintf(fp,\"\\n\");\n",
        "  }\n",
        "  fmatrix_free_on_host(&tmp);\n",
        "  // Close file\n",
        "  fclose(fp);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void fmatrix_create_random_on_device_kernel(fmatrix M) {\n",
        "    // choose a seed (here: the same each launch)\n",
        "    unsigned long seed = 0;\n",
        "    int sequence = 0;\n",
        "    // first, initialize the random numbers\n",
        "    curandState state;\n",
        "    curand_init(seed, sequence, 0, &state);\n",
        "    for (int i = 0; i < fmatrix_elements(M); ++i) {\n",
        "        // curand_uniform creates numbers between 0 and 1\n",
        "        M.data[i] = (curand_uniform(&state)-0.5)*2.0;\n",
        "    }\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_create_random_on_device(int rows, int cols) {\n",
        "    // Create an uninitialized matrix on the device\n",
        "    fmatrix M = fmatrix_create_on_device(rows,cols);\n",
        "    // Call a kernel with a single thread to fill the values\n",
        "    fmatrix_create_random_on_device_kernel<<<1,1>>>(M);\n",
        "\n",
        "    return M;\n",
        "}\n",
        "\n",
        "/* Count the number of rows and columns in a csv files (without headers) */\n",
        "void count_elements_in_csv(const char* filename, int* rows, int* cols) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "\n",
        "  *rows = 0;\n",
        "  *cols = 0;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int tempcols = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "          ++tempcols;\n",
        "        }\n",
        "        if (tempcols > *cols) {\n",
        "           *cols = tempcols;\n",
        "        }\n",
        "        ++(*rows);\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "/** Read the data from a csv file into an fmatrix on the host.\n",
        " *  Careful: We assume that the matrix has the right dimensions!\n",
        " *  Use count_elements_in_csv(...) to get the dimensions if\n",
        " *  unknown.\n",
        " */\n",
        "void fmatrix_fill_from_csv(fmatrix h_M,const char* filename) {\n",
        "  // Note: for the sake of convenience, we use some C++ functions here\n",
        "  using namespace std;\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "    while (getline(infile, row_as_string, '\\n')) {\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "        int col = 0;\n",
        "        while (getline(line_stream, value, ',')) {\n",
        "\t\t\t\t\tgetfm(h_M,row,col) = strtod(value.c_str(), NULL);\n",
        "          ++col;\n",
        "\t\t\t\t}\n",
        "        ++row;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n",
        "fmatrix fmatrix_device_from_csv(const char* filename) {\n",
        "  // first read the file to count the number of elements\n",
        "  int rows = 0;\n",
        "  int cols = 0;\n",
        "  count_elements_in_csv(filename,&rows,&cols);\n",
        "\n",
        "  // allocate the matrix on the host\n",
        "  fmatrix h_M = fmatrix_create_on_host(rows,cols);\n",
        "\n",
        "  // read the data into the host matrix\n",
        "  fmatrix_fill_from_csv(h_M,filename);\n",
        "\n",
        "  // copy the matrix to the device\n",
        "  fmatrix M = fmatrix_copy_to_device(h_M);\n",
        "\n",
        "  // destroy the host matrix\n",
        "  fmatrix_free_on_host(&h_M);\n",
        "\n",
        "  return M;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fmatrix.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsKLTK8ELOdN"
      },
      "source": [
        "## Data I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD7rmOBmWfsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba94700f-c0be-4b3c-86fe-633f7e270d8e"
      },
      "source": [
        "%%writefile read_csv.cuh\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef read_csv_H\n",
        "#define read_csv_H\n",
        "\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol);\n",
        "\n",
        "#endif"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting read_csv.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeedFsZ_WQx0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52c78f6-42f0-42fd-8670-455b0fd1b482"
      },
      "source": [
        "%%writefile read_csv.cu\n",
        "\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"cuda_stuff.cuh\" // for matrix indexing\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for reading the dataset from a file\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Read a csv file with a given number of rows and columns */\n",
        "void read_csv(const char* filename, float* data_array,int nbrow,int nbcol) {\n",
        "  string row_as_string;\n",
        "  string value;\n",
        "  double ioTemp;\n",
        "  ifstream infile;\n",
        "  infile.open(filename, ifstream::in);\n",
        "  int row_count = 0;\n",
        "\tif (infile.is_open())\n",
        "  {\n",
        "      // read the headers (and discard)\n",
        "\t\t\tgetline(infile, row_as_string, '\\n');\n",
        "      cout << \"headers: \" << row_as_string << \"!\" << std::endl;\n",
        "      for(int i = 0; i < nbrow; i++){\n",
        "  \t\t\tgetline(infile, row_as_string, '\\n');\n",
        "        // cout << \"read line \" << row_as_string << \"!\" << std::endl;\n",
        "\t\t\t\tistringstream line_stream(row_as_string);\n",
        "\t\t\t  for(int j = 0; j < nbcol; j++){\n",
        "          getline(line_stream, value, ',');\n",
        "\t\t\t\t\tioTemp = strtod(value.c_str(), NULL);\n",
        "          // cout << \"(\"<<i<<\",\"<<j<<\") = \"<< ioTemp << std::endl;\n",
        "\n",
        "\t\t\t\t\tdata_array[IDX2C(i,j,nbrow)] = ioTemp;\n",
        "\n",
        "\t\t\t\t}\n",
        "        ++row_count;\n",
        "\t\t\t}\n",
        "\t\tinfile.close();\n",
        "    cout << \"Read \" << row_count << \" rows.\" << std::endl;\n",
        "\t}\n",
        "\telse cout << \"Cannot open file.\" << endl;\n",
        "}\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting read_csv.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex8ilQdYYroU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce575a20-07a9-4854-a94a-c09b4f2e5e2c"
      },
      "source": [
        "%%writefile preprocess_data.cuh\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#ifndef preprocess_data_H\n",
        "#define preprocess_data_H\n",
        "\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels );\n",
        "\n",
        "#endif"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting preprocess_data.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaeUdw_KYaCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcfcfe14-ecd0-412e-ee13-6f050f36277c"
      },
      "source": [
        "%%writefile preprocess_data.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"preprocess_data.cuh\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "/* transform matrix index to vector offset\n",
        "   Since CUDA uses column major,\n",
        "   ld = number of rows\n",
        "   Example of use: a[IDX2C(0, 1, 50)] */\n",
        "#define IDX2C(i,j,ld) (((j)*(ld))+(i))\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "/////////////////////////////////////////////////////////\n",
        "// Functions for preprocessing the data set\n",
        "/////////////////////////////////////////////////////////\n",
        "\n",
        "/* Split data into inputs and labels. Allocated memory for inputs and labels.\n",
        "   Since cuBLAS is column major, each input is in a column.\n",
        "   We also add 1.0 as first element to each input vector.\n",
        "*/\n",
        "void get_inputs_and_labels(float* data_array, float** input_array, float** label_array, int nbrows, int nbcols, int nb_inputs, int nb_labels ) {\n",
        "    // The inputs are the first nbrows-1 columns.\n",
        "    // The labels are the last column (index nbrows-1), booleanized\n",
        "    // by the condition >= above_threshold\n",
        "    *input_array = (float *)malloc(nbrows * nb_inputs * sizeof(float));\n",
        "    *label_array = (float *)malloc(nbrows * nb_labels * sizeof(float));\n",
        "    //cout << &input_array << \" and \"<< &label_array << \" data \" << data_array << std::endl;\n",
        "    cout << \"Allocated memory for inputs: \" << nbrows << \" rows, \"<< nb_inputs << \" columns.\" << std::endl;\n",
        "    cout << \"Allocated memory for labels: \" << nbrows << \" rows, \"<< nb_labels << \" columns.\" << std::endl;\n",
        "\n",
        "    // Copy the data to X\n",
        "    for(int i = 0; i < nbrows; i++){\n",
        "      // Set the first element of each x to 1\n",
        "      (*input_array)[IDX2C(0,i,nb_inputs)] = 1.0;\n",
        "      // Copy the rest of x\n",
        "\t\t\tfor(int j = 1; j < nb_inputs; j++){\n",
        "\t\t\t\t(*input_array)[IDX2C(j,i,nb_inputs)] = data_array[IDX2C(i,j-1,nbrows)];\n",
        "\t\t\t}\n",
        "      float median_house_value = data_array[IDX2C(i,nbcols-1,nbrows)];\n",
        "      (*label_array)[IDX2C(0,i,nb_labels)] = 0.0;\n",
        "      (*label_array)[IDX2C(1,i,nb_labels)] = 0.0;\n",
        "      if (median_house_value >= above_threshold) {\n",
        "        (*label_array)[IDX2C(0,i,nb_labels)] = 1.0;\n",
        "      } else {\n",
        "        (*label_array)[IDX2C(1,i,nb_labels)] = 1.0;\n",
        "      }\n",
        "\t\t}\n",
        "\n",
        "    // Show some entries for double checking\n",
        "    cout << \"Inputs (first \"<<print_rows<<\"):\" << std::endl;\n",
        "\t  for(int j = 0; j < nb_inputs; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*input_array)[IDX2C(j,i,nb_inputs)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "    cout << \"Labels (first \"<<print_rows<<\"):\" << std::endl;\n",
        "    for(int j = 0; j < nb_labels; j++){\n",
        "      for(int i = 0; i < nbrows && i < print_rows; i++){\n",
        "\t\t\t\tcout << (*label_array)[IDX2C(j,i,nb_labels)] << \"\\t\";\n",
        "\t\t\t}\n",
        "      cout << \"\\n\";\n",
        "\t\t}\n",
        "}"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting preprocess_data.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHy3EAid05oA"
      },
      "source": [],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code That You Write"
      ],
      "metadata": {
        "id": "rR-9WFucUWLC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWS3hlAecOc"
      },
      "source": [
        "## Classifier Math"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK_tmB-xbZKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b43922-46b8-4e48-ec4f-f6c561d7f13d"
      },
      "source": [
        "%%writefile classifier_math.cuh\n",
        "#ifndef classifier_math_H\n",
        "#define classifier_math_H\n",
        "\n",
        "#include \"cublas_v2.h\"\n",
        "\n",
        "#include \"fmatrix.cuh\"\n",
        "\n",
        "/** Returns a random float between min and max (including). */\n",
        "float float_rand( float min, float max );\n",
        "\n",
        "/** Initialize W with Xavier's method,\n",
        " *  scaled by a. */\n",
        "void xavier_weight_init(float a, fmatrix W);\n",
        "\n",
        "/** Compute the softmax for each column of Z and store in P **/\n",
        "void softmax_col(fmatrix P,fmatrix Z);\n",
        "\n",
        "///////////////////////////////////\n",
        "// TO BE COMPLETED\n",
        "// ... add your matrix math here\n",
        "///////////////////////////////////\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C);\n",
        "\n",
        "void mat_transp_mul(float alpha, fmatrix d_A, fmatrix d_B, float beta, fmatrix d_C, int inv);\n",
        "\n",
        "#endif"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting classifier_math.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgXwgv6Bbo-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b265be-a363-4d38-f2c4-f6e3ff8850c7"
      },
      "source": [
        "%%writefile classifier_math.cu\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"cuda_stuff.cuh\"\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_transp_mul_kernel(fmatrix Z,float a,fmatrix X,fmatrix Y) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / Z.rows;\n",
        "    int i = idx % Z.rows;\n",
        "    // printf(\"(%d,%d) \\n\",i,j);\n",
        "    if (i < Z.rows && j < Z.cols ){\n",
        "        getfm(Z,i,j) = 0.0;\n",
        "        for (int k = 0; k< X.rows ; ++k) {\n",
        "          // printf(\"%f + %f * %f * %f\\n\", getfm(Z,i,j), a,getfm(X,k,i),getfm(Y,k,j));\n",
        "          getfm(Z,i,j) += a*getfm(X,k,i)*getfm(Y,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "void fmatrix_transp_mul(fmatrix Z,float a,fmatrix X,fmatrix Y) {\n",
        "    assert(Z.rows == X.cols);\n",
        "    assert(Z.cols == Y.cols);\n",
        "    assert(X.rows == Y.rows);\n",
        "\n",
        "    // printf(\"Z(%d,%d) elements %d \\n\",Z.rows,Z.cols,fmatrix_elements(Z));\n",
        "\n",
        "    int threadsPerBlock = fmatrix_elements(Z);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_transp_mul_kernel<<< blocksPerGrid, threadsPerBlock >>>(Z,a,X,Y);\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "}\n",
        "\n",
        "\n",
        "void mat_transp_mul(float alpha, fmatrix d_A, fmatrix d_B, float beta, fmatrix d_C, int inv){\n",
        "  /* TODO */\n",
        "  int m=d_A.rows;\n",
        "  int k=d_A.cols;\n",
        "  int n=d_B.cols;\n",
        "  if (inv == 0) {\n",
        "    m=d_A.cols;\n",
        "    k=d_A.rows;\n",
        "    n=d_B.cols;\n",
        "    }\n",
        "  else if (inv ==1) {\n",
        "    n=d_B.rows;\n",
        "  }\n",
        "\n",
        "  int lda=d_A.rows,ldb=d_B.rows,ldc=d_C.rows;\n",
        "\n",
        "  const float *alf = &alpha;\n",
        "  const float *bet= &beta;\n",
        "\n",
        "  // Create a handle for CUBLAS\n",
        "  cublasHandle_t handle;\n",
        "  cublasCreate(&handle);\n",
        "\n",
        "\n",
        "  //clock_t start, end;\n",
        "  //float cpu_time_used;\n",
        "  //start = clock();\n",
        "  // Do the actual multiplication\n",
        "  if (inv == 0)\n",
        "  {cublasSgemm(handle, CUBLAS_OP_T, CUBLAS_OP_N, m, n, k, alf, d_A.data, lda, d_B.data, ldb, bet, d_C.data, ldc);}\n",
        "  else\n",
        "  {\n",
        "      cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_T, m, n, k, alf, d_A.data, lda, d_B.data, ldb, bet, d_C.data, ldc);}\n",
        "\n",
        "  // Destroy the handle\n",
        "  cublasDestroy(handle);\n",
        "\n",
        "}\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Auxiliary function\n",
        "/////////////////////////////////////////////////////////\n",
        "// generate random numbers in interval [min,max]\n",
        "float float_rand( float min, float max )\n",
        "{\n",
        "    float scale = rand() / (float) RAND_MAX; /* [0, 1.0] */\n",
        "    return min + scale * ( max - min );      /* [min, max] */\n",
        "}\n",
        "\n",
        "void xavier_weight_init(float a, fmatrix W){\n",
        "    for (int j = 0; j < W.rows  ; ++j) {\n",
        "      for (int i = 0; i < W.cols  ; ++i) {\n",
        "          getfm(W,j,i) = a * (1.0/sqrt(W.cols+W.rows)) * float_rand(-1.0,1.0);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__\n",
        "void softmax_col_kernel(float *Z, float *P, int nb_ColZ, int nb_LigneZ) {\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\n",
        "    float s=0;\n",
        "\n",
        "\n",
        "    if (col < nb_ColZ){\n",
        "        for (int k=0; k<nb_LigneZ; k++){\n",
        "            s+=exp(Z[col*nb_LigneZ+k]);\n",
        "        }\n",
        "        for (int k=0; k<nb_LigneZ; k++) {\n",
        "            P[col*nb_LigneZ + k]=exp(Z[col*nb_LigneZ+k])/s;\n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void softmax_col(fmatrix P,fmatrix Z) {\n",
        "    assert(P.cols==Z.cols);\n",
        "    assert(P.rows==Z.rows);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the softmax here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "    int blocksize = 100;\n",
        "    dim3 dimBlock (blocksize);\n",
        "    dim3 dimGrid(ceil( Z.cols / (float)blocksize));\n",
        "    softmax_col_kernel <<< dimGrid, dimBlock >>>(Z.data, P.data, Z.cols, Z.rows);\n",
        "\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "\n",
        "///////////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_multiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.cols; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,i,k)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B*C */\n",
        "void fmatrix_mult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.rows);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.cols == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n",
        "\n",
        "//// Multiplication de matrice avec transposé\n",
        "\n",
        "\n",
        "__global__\n",
        "void fmatrix_tmultiplication_kernel(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // Each thread multiplies one row of B with one column of C\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    int j = idx / A.rows;\n",
        "    int i = idx % A.rows;\n",
        "    if (i < A.rows && j < A.cols ){\n",
        "        getfm(A,i,j) = 0.0;\n",
        "        for (int k = 0; k < B.rows; ++k) {\n",
        "          getfm(A,i,j) += f*getfm(B,k,i)*getfm(C,k,j);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/* Compute A = f*B^T*C */\n",
        "void fmatrix_tmult(fmatrix A, float f, fmatrix B, fmatrix C) {\n",
        "    // First let's check for errors in the argument M.\n",
        "    // This can help a LOT when debugging.\n",
        "    // A,B,C need to have nonzero pointers etc.\n",
        "    // fmatrix_assert(A);\n",
        "    // fmatrix_assert(B);\n",
        "    // fmatrix_assert(C);\n",
        "    assert(A.rows == B.cols);\n",
        "    assert(A.cols == C.cols);\n",
        "    assert(B.rows == C.rows);\n",
        "\n",
        "    // take one thread per element, and distribute\n",
        "    // over as many blocks as necessary given\n",
        "    // the hardware limit on the number of threads per block\n",
        "    int threadsPerBlock = fmatrix_elements(A);\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    fmatrix_multiplication_kernel<<< blocksPerGrid, threadsPerBlock >>>(A,f,B,C);\n",
        "    // check for errors\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "    // wait for the kernel to finish\n",
        "    device_synchronize();\n",
        "}\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting classifier_math.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6G22rDKR3rv"
      },
      "source": [
        "## Evaluating Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd7Vmzo72hpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d139436b-393c-4a91-a03a-1755bf39b220"
      },
      "source": [
        "%%writefile evaluate_accuracy.cuh\n",
        "\n",
        "/** Evaluate the accuracy of a linear classifier with D x M weight\n",
        " *  matrix W, using D x N input data X and M x N output labels Y.\n",
        " *  Z is a temporary matrix with dimensions M x N,\n",
        " *  which must be previously allocated.\n",
        " */\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z);\n",
        "\n",
        "/** Compute the logloss given M x N matrices of\n",
        " *  probabilities P and output labels Y\n",
        " *  and stores it in J.\n",
        " *  J is a matrix with dimensions 1 x 1,\n",
        " *  which must be previously allocated.\n",
        " *  logloss = sum_j -Y(j,k)*log(P(j,k))\n",
        " */\n",
        "float evaluate_logloss(fmatrix d_P,fmatrix d_Y);"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate_accuracy.cuh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0Z-9B4a2dwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300ceedf-97a3-48f6-bb2e-07e9f2b02a59"
      },
      "source": [
        "%%writefile evaluate_accuracy.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include <assert.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__\n",
        "void evaluate_accuracy_kernel(fmatrix d_Y,fmatrix d_Z,int* count) {\n",
        "    int idx = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "    if (idx < d_Z.cols){\n",
        "        float z_max = getfm(d_Z,0,idx);\n",
        "        int i_max = 0;\n",
        "        for (int i = 1; i < d_Z.rows; ++i) {\n",
        "          if (getfm(d_Z,i,idx)>z_max) {\n",
        "                z_max = getfm(d_Z,i,idx);\n",
        "                i_max = i;\n",
        "          }\n",
        "        }\n",
        "      if (getfm(d_Y,i_max,idx)>=0.5f) {\n",
        "          atomicAdd(count,1);\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "float evaluate_accuracy(fmatrix d_W,fmatrix d_X,fmatrix d_Y,fmatrix d_Z) {\n",
        "    assert(d_Y.cols == d_Z.cols);\n",
        "    assert(d_Y.rows == d_Z.rows);\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 1. compute Z = W^T X\n",
        "  // --> each column of Z corresponds to one input\n",
        "  //////////////////////////////////////////\n",
        "  mat_transp_mul(1.0, d_W, d_X, 0.0, d_Z,0);\n",
        "\n",
        "  /*********************************\n",
        "  / TO BE COMPLETED\n",
        "  / ... compute Z = W^T X here ...\n",
        "  **********************************/\n",
        "\n",
        "  //////////////////////////////////////////\n",
        "  // 2. For each column z of Z,\n",
        "  // find argmax_k z_k\n",
        "  //////////////////////////////////////////\n",
        "\n",
        "  int true_class = 0;\n",
        "\n",
        "  int* d_count = 0;\n",
        "  gpuErrchk(cudaMalloc((void **)&d_count, sizeof(int)));\n",
        "  gpuErrchk(\n",
        "        cudaMemcpy( d_count, &true_class, sizeof(int), cudaMemcpyHostToDevice )\n",
        "  );\n",
        "\n",
        "    int threadsPerBlock = d_Z.cols;\n",
        "    int blocksPerGrid = 1;\n",
        "    if (threadsPerBlock > THREADS_PER_BLOCK){\n",
        "        blocksPerGrid = (threadsPerBlock-1)/THREADS_PER_BLOCK+1;\n",
        "        threadsPerBlock = THREADS_PER_BLOCK;\n",
        "    }\n",
        "    evaluate_accuracy_kernel<<< blocksPerGrid, threadsPerBlock >>>(d_Y,d_Z,d_count);\n",
        "    device_synchronize();\n",
        "    gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "  gpuErrchk(\n",
        "          cudaMemcpy(&true_class, d_count, sizeof(int), cudaMemcpyDeviceToHost )\n",
        "  );\n",
        "\n",
        "  //printf(\"Correct results: %d out of %d\\n\",true_class,nb_tested);\n",
        "  //printf(\"Accuracy: %f\\n\",(float)true_class/(float)nb_tested);\n",
        "  return (float)true_class/(float)d_Z.cols;\n",
        "}\n",
        "\n",
        "\n",
        "float evaluate_logloss(fmatrix d_P,fmatrix d_Y) {\n",
        "    assert(d_Y.cols == d_P.cols);\n",
        "    assert(d_Y.rows == d_P.rows);\n",
        "\n",
        "  float J = 0.0;\n",
        "\n",
        "    ///////////////////////////////////\n",
        "    // TO BE COMPLETED\n",
        "    // ... compute the logloss here ...\n",
        "    ///////////////////////////////////\n",
        "\n",
        "    for (int i =0 ; i <d_P.cols; i++)\n",
        "    {\n",
        "    for (int k = 0 ; k < d_P.rows; k++)\n",
        "        {\n",
        "            J+=getfm(d_Y,k,i)* log(getfm(d_P,k,i));\n",
        "\n",
        "        }\n",
        "    }\n",
        "  J=-J/d_P.cols;\n",
        "\n",
        "  return J;\n",
        "}\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate_accuracy.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!shuf sample_data/california_housing_train.csv > california_housing_train_shuff.csv"
      ],
      "metadata": {
        "id": "UY2VxLizKMRs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AwZh8WULi_F"
      },
      "source": [
        "## Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWO5p1NeHE9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3b5b9f-3d2a-41b9-d03f-8dc9eb90bfd9"
      },
      "source": [
        "%%writefile linear_classification.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <fstream>\n",
        "\n",
        "/*Matrix multiplication functions and other auxiliary functions*/\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"read_csv.cuh\"\n",
        "#include \"preprocess_data.cuh\"\n",
        "#include \"classifier_math.cuh\"\n",
        "#include \"evaluate_accuracy.cuh\"\n",
        "/* Includes, cuda */\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "//Number of thread per block\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "/* Constants for housing data set */\n",
        "#define data_columns  (9)\n",
        "#define above_threshold (265000.0)\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Number of rows in arrays to print for debugging\n",
        "/////////////////////////////////////////////////////////\n",
        "#define print_rows (10)\n",
        "\n",
        "\n",
        "/////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "/////////////////////////////////////////////////////////\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    size_t N_train = 12000; // 4; //12000; // points for training (Google: 12000)\n",
        "    size_t N_test = 5000; // 2; // 5000; // points for validation (Google: 5000)\n",
        "    size_t N = N_train;\n",
        "    size_t Nall = N_train+N_test;\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Reading the data set\n",
        "    /////////////////////////////////////////////////////////\n",
        "    fmatrix alldata = fmatrix_create_on_host(Nall,data_columns);\n",
        "    read_csv(\"sample_data/california_housing_train_shuff.csv\",alldata.data,Nall,data_columns);\n",
        "    //fmatrix_print(alldata);\n",
        "\n",
        "    size_t D = data_columns-1+1; // remove output column, add column with const. 1.0\n",
        "    size_t M = 2; // number of labels (one-hot encoding)\n",
        "    fmatrix Xall = fmatrix_create_on_host(D,Nall);\n",
        "    fmatrix Yall = fmatrix_create_on_host(M,Nall);\n",
        "    get_inputs_and_labels(alldata.data,&Xall.data,&Yall.data,Nall,data_columns,D,M);\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Inputs and labels are now available in X and Y.\n",
        "    // Each input is a column in X; X is of dimension D x N\n",
        "    // each label is a column in Y; Y is of dimension M x N\n",
        "    /////////////////////////////////////////////////////////\n",
        "\n",
        "    // Logfile\n",
        "    FILE* fp = fopen(\"log.txt\", \"w\");\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Parameters for Stochastic Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    int nb_iter = 100;           // defeault: 10;\n",
        "    int periods = nb_iter;      // reporting period\n",
        "    int batch_size = N;         // defeault: N;\n",
        "    float learning_rate = 1e-7; // default: 1e-7\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Memory Allocation and Initialization\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // take X,Y to be the first N columns of all data\n",
        "    fmatrix h_X = fmatrix_subcolumns(Xall,0,N);\n",
        "    fmatrix h_Y = fmatrix_subcolumns(Yall,0,N);\n",
        "    fmatrix h_Xtest = fmatrix_subcolumns(Xall,N,Nall);\n",
        "    fmatrix h_Ytest = fmatrix_subcolumns(Yall,N,Nall);\n",
        "    fmatrix h_W = fmatrix_create_on_host(D,M);\n",
        "    fmatrix h_J = fmatrix_create_on_host(1,1);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Initializing Weight Matrix\n",
        "    // its dimension is D x M\n",
        "    /////////////////////////////////////////////////////////\n",
        "    xavier_weight_init(1.0,h_W);\n",
        "\n",
        "    //////////////////////////////\n",
        "    // Copy data to device      //\n",
        "    //////////////////////////////\n",
        "    fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "    fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "    fmatrix d_Xtest = fmatrix_copy_to_device(h_Xtest);\n",
        "    fmatrix d_Ytest = fmatrix_copy_to_device(h_Ytest);\n",
        "    fmatrix d_W = fmatrix_copy_to_device(h_W);\n",
        "    fmatrix d_J = fmatrix_copy_to_device(h_J);\n",
        "\n",
        "    /////////////////////////////////////////\n",
        "    // Create auxiliary matrices on device //\n",
        "    /////////////////////////////////////////\n",
        "    fmatrix d_Z = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_P = fmatrix_create_on_device(M,batch_size);\n",
        "    fmatrix d_G = fmatrix_create_on_device(D,M);\n",
        "    // auxiliary matrix for computing Z=W^T X on test data\n",
        "    fmatrix d_Ztest = fmatrix_create_on_device(M,d_Xtest.cols);\n",
        "\n",
        "    /////////////////////////////////////////////////////////\n",
        "    // Batch Gradient Descent\n",
        "    /////////////////////////////////////////////////////////\n",
        "    //fmatrix_device_print(d_X);\n",
        "    //fmatrix_device_print(d_W);\n",
        "\n",
        "     /* Evaluate the accuracy */\n",
        "    float accuracy = 0;\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"initial accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    float J = 0;\n",
        "\n",
        "    clock_t tstart_total, tend;\n",
        "    tstart_total = clock();\n",
        "\n",
        "    int batch_pointer = 0;\n",
        "    for (int i = 0; i < nb_iter; ++i )  {\n",
        "\n",
        "        //printf(\"W:\\n\");fmatrix_device_print(d_W);\n",
        "        //printf(\"X:\\n\");fmatrix_device_print(d_X);\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // compute Z = W^T X\n",
        "      // --> each column z of Z corresponds to one column x of X\n",
        "\n",
        "      ////////////////////////////////\n",
        "\n",
        "\n",
        "      ///////////////////////////////////\n",
        "      fmatrix h_X=fmatrix_subcolumns(Xall,batch_pointer, batch_pointer+batch_size);\n",
        "      fmatrix d_X = fmatrix_copy_to_device(h_X);\n",
        "      fmatrix h_Y = fmatrix_subcolumns(Yall,batch_pointer,  batch_pointer+batch_size);\n",
        "      fmatrix d_Y = fmatrix_copy_to_device(h_Y);\n",
        "\n",
        "        mat_transp_mul(1.0, d_W, d_X, 0.0, d_Z, 0);\n",
        "        //printf(\"Z:\\n\"); fmatrix_device_print(d_Z);\n",
        "        //fmatrix d_Z2 = fmatrix_create_on_device(M,batch_size);\n",
        "        //fmatrix_transp_mul(d_Z2,1.0,d_W,d_X);\n",
        "       //printf(\"Z2:\\n\"); fmatrix_device_print(d_Z2);\n",
        "\n",
        "\n",
        "      ///////////////////////////////////\n",
        "\n",
        "\n",
        "\n",
        "      ////////////////////////////////\n",
        "      // For each column z of Z, compute activation p(z);\n",
        "      // then update W\n",
        "      ////////////////////////////////\n",
        "\n",
        "      // compute softmax per column of Z and store in Z\n",
        "\n",
        "    ///////////////////////////////////\n",
        "        softmax_col(d_P, d_Z);\n",
        "        //printf(\"Z:\\n\"); fmatrix_device_print(d_Z);\n",
        "        //printf(\"P:\\n\"); fmatrix_device_print(d_P);\n",
        "        fmatrix h_P = fmatrix_copy_to_host(d_P);\n",
        "\n",
        "    ///////////////////////////////////\n",
        "\n",
        "      // evaluate logloss (for reporting only)\n",
        "\n",
        "    ///////////////////////////////////\n",
        "\n",
        "        J=evaluate_logloss(h_P, h_Y);\n",
        "        //printf (\"Jiiiiiii %f \\n\", J);\n",
        "    ///////////////////////////////////\n",
        "\n",
        "\n",
        "      // Q:=P-Y\n",
        "      // compute gradient G = 1/batch_size XQ^T\n",
        "      // ... possibly work with G here ...\n",
        "      // update weights W = W - learning_rate*G\n",
        "\n",
        "    ///////////////////////////////////\n",
        "        fmatrix h_Q = fmatrix_create_on_host(M,batch_size);\n",
        "        for (int i = 0 ; i < h_Q.rows; i++){\n",
        "            for (int j = 0 ; j<h_Q.cols; j++){\n",
        "                h_Q.data[IDX2C(i,j,h_Q.rows)]= getfm(h_P,i,j)-getfm(h_Y,i,j);\n",
        "      }\n",
        "    }\n",
        "\n",
        "\n",
        "        //fmatrix_print(h_Q);\n",
        "        fmatrix d_Q = fmatrix_copy_to_device(h_Q);\n",
        "\n",
        "\n",
        "        mat_transp_mul(1.0, d_X, d_Q, 0.0, d_G, 1);\n",
        "\n",
        "        fmatrix h_G = fmatrix_copy_to_host(d_G);\n",
        "        //printf(\"G:\\n\"); fmatrix_print(h_G);\n",
        "\n",
        "        fmatrix_data_to_device(h_G,d_G);\n",
        "        for (int i = 0 ; i < h_W.rows; i++){\n",
        "          for (int j = 0 ; j<h_W.cols; j++){\n",
        "              h_W.data[IDX2C(i,j,h_W.rows)]=getfm(h_W,i,j)- learning_rate/batch_size* getfm(h_G,i,j);\n",
        "          }\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "      fmatrix_data_to_device(h_W,d_W);\n",
        "      //printf(\"W_h:\\n\");fmatrix_print(h_W);\n",
        "\n",
        "\n",
        "\n",
        "      // For reporting, compute logloss and accuracy\n",
        "\n",
        "\n",
        "\n",
        "        float accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "        printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
        "        fprintf(fp, \"%f,%f\\n\", J, accuracy);\n",
        "\n",
        "\n",
        " }\n",
        "    tend = clock();\n",
        "    float duration = ((float)(tend-tstart_total))/CLOCKS_PER_SEC;\n",
        "    printf(\"Duration (s): %f\\n\",duration);\n",
        "    /* Evaluate the accuracy */\n",
        "    accuracy = evaluate_accuracy(d_W,d_Xtest,d_Ytest,d_Ztest);\n",
        "    printf(\"final accuracy: %f\\n\",accuracy);\n",
        "\n",
        "    printf(\"final weights: \\n\");\n",
        "    fmatrix_device_print(d_W);\n",
        "\n",
        "    /* Memory clean up */\n",
        "    /** No need to free h_X, h_Y, h_Xtest, h_Ytest since\n",
        "     *  they all point to Xall\n",
        "     */\n",
        "    fmatrix_free_on_host(&h_W);\n",
        "    fmatrix_free_on_host(&Xall);\n",
        "    fmatrix_free_on_host(&Yall);\n",
        "\n",
        "    fmatrix_free_on_device(&d_X);\n",
        "    fmatrix_free_on_device(&d_Y);\n",
        "    fmatrix_free_on_device(&d_Xtest);\n",
        "    fmatrix_free_on_device(&d_Ytest);\n",
        "    fmatrix_free_on_device(&d_W);\n",
        "    fmatrix_free_on_device(&d_Z);\n",
        "    fmatrix_free_on_device(&d_J);\n",
        "\n",
        "    // Close log file\n",
        "    fclose(fp);\n",
        "}"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting linear_classification.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrATC8s9LsDw"
      },
      "source": [
        "# Compiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z52xd0NMRKXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ccbb4c-7699-4330-e041-ed29a6ceef85"
      },
      "source": [
        "!nvcc -Wno-deprecated-gpu-targets -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(226)\u001b[0m: \u001b[01;35mwarning\u001b[0m #780-D: reference is to variable \u001b[01m\"i\"\u001b[0m\u001b[32m (declared at line 131)\u001b[0m -- under old for-init scoping rules it would have been variable \u001b[01m\"i\"\u001b[0m\u001b[32m (declared at line 191)\u001b[0m\n",
            "          printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
            "                                                         ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(226)\u001b[0m: \u001b[01;35mwarning\u001b[0m #780-D: reference is to variable \u001b[01m\"i\"\u001b[0m\u001b[32m (declared at line 131)\u001b[0m -- under old for-init scoping rules it would have been variable \u001b[01m\"i\"\u001b[0m\u001b[32m (declared at line 191)\u001b[0m\n",
            "          printf(\"iter: %d, logloss: %f, accuracy: %f\\n\",i,J, accuracy);\n",
            "                                                         ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(74)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"periods\"\u001b[0m was declared but never referenced\n",
            "      int periods = nb_iter;\n",
            "          ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZVqTfXcLvPr"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GcUSYjJ1EEx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV_vFkIT7fV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462be3ff-66dc-4697-fce0-220ce5f39cbc"
      },
      "source": [
        "%%time\n",
        "!./a.out"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot open file.\n",
            "Allocated memory for inputs: 6 rows, 9 columns.\n",
            "Allocated memory for labels: 6 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.000000\n",
            "iter: 0, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 1, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 2, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 3, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 4, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 5, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 6, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 7, logloss: 0.836569, accuracy: 0.000000\n",
            "iter: 8, logloss: 0.836568, accuracy: 0.000000\n",
            "iter: 9, logloss: 0.836568, accuracy: 0.000000\n",
            "Duration (s): 0.106140\n",
            "final accuracy: 0.000000\n",
            "final weights: \n",
            "[\n",
            "0.205140,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "CPU times: user 14.5 ms, sys: 2.23 ms, total: 16.7 ms\n",
            "Wall time: 1.41 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIyxh0ClrIz"
      },
      "source": [
        "Let's plot the logloss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR2kCNEIlpqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "0a7f58fe-6e30-406c-f754-36a5bef3db5c"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = pd.read_csv('log.txt',sep=',',header=None)\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(data[0],label=\"logloss\")\n",
        "ax2=ax.twinx()\n",
        "ax2.plot([], [])\n",
        "ax2.plot(data[1],label=\"accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17aUKkNJqTDZ"
      },
      "source": [
        "# Debugging\n",
        "Compile with debugging info on the host (`-g`) and device (`-G`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dtB5QKcWQ5M2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcfLGo1UrMq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241cd71d-97e6-41be-fd9f-51838620a247"
      },
      "source": [
        "!nvcc -g -G -I cuda-samples/Common/ -L/usr/local/cuda/include -lcublas -lcusolver linear_classification.cu read_csv.cu preprocess_data.cu evaluate_accuracy.cu fmatrix.cu classifier_math.cu cuda_stuff.cu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(76)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"learning_rate\"\u001b[0m was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01mlinear_classification.cu(130)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"batch_pointer\"\u001b[0m was declared but never referenced\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkuaGO10rRm9"
      },
      "source": [
        "Run the debugger cuda-gdb, stopping at the first error that is detected. Shows first the call stack on the GPU, the values of local variables, then the call stack on the host (thread 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ8nAtzGTRgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7caff4da-8a5b-40ce-ffe8-944dc41c7afb"
      },
      "source": [
        "! printf \"set cuda memcheck on\\nset cuda api_failures stop\\ncatch throw\\nr\\nbt\\ninfo locals\\nthread 1\\nbt\\n\" > tmp.txt\n",
        "! cat tmp.txt\n",
        "! cuda-gdb -batch -x tmp.txt ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set cuda memcheck on\n",
            "set cuda api_failures stop\n",
            "catch throw\n",
            "r\n",
            "bt\n",
            "info locals\n",
            "thread 1\n",
            "bt\n",
            "Catchpoint 1 (throw)\n",
            "warning: Error disabling address space randomization: Operation not permitted\n",
            "[Thread debugging using libthread_db enabled]\n",
            "Using host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n",
            "[New Thread 0x7fad67250000 (LWP 6223)]\n",
            "[Detaching after fork from child process 6224]\n",
            "[New Thread 0x7fad66723000 (LWP 6233)]\n",
            "[New Thread 0x7fad65f22000 (LWP 6234)]\n",
            "original matrix:\n",
            "[\n",
            "0.480439;\n",
            "-0.123098\n",
            "]\n",
            "[\n",
            "0.480439\n",
            "]\n",
            "a.out: classifier_math.cu:111: void fmatrix_tmult(fmatrix, float, fmatrix, fmatrix): Assertion `A.rows == B.cols' failed.\n",
            "\n",
            "Thread 1 \"a.out\" received signal SIGABRT, Aborted.\n",
            "0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#1  0x00007fad69a17859 in abort () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#2  0x00007fad69a17729 in ?? () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#3  0x00007fad69a28fd6 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#4  0x00005652aac0a584 in fmatrix_tmult (A=..., f=1, B=..., C=...) at classifier_math.cu:111\n",
            "#5  0x00005652aac0a7c7 in main () at test.cu:13\n",
            "No symbol table info available.\n",
            "[Switching to thread 1 (Thread 0x7fad699f2000 (LWP 6218))]\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#0  0x00007fad69a3800b in raise () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#1  0x00007fad69a17859 in abort () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#2  0x00007fad69a17729 in ?? () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#3  0x00007fad69a28fd6 in __assert_fail () from /lib/x86_64-linux-gnu/libc.so.6\n",
            "#4  0x00005652aac0a584 in fmatrix_tmult (A=..., f=1, B=..., C=...) at classifier_math.cu:111\n",
            "#5  0x00005652aac0a7c7 in main () at test.cu:13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGJ6uVNBVHUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d044452-1f0e-4e79-9173-a176dc01a260"
      },
      "source": [
        "!cuda-memcheck ./a.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= CUDA-MEMCHECK\n",
            "========= This tool is deprecated and will be removed in a future release of the CUDA toolkit\n",
            "========= Please use the compute-sanitizer tool as a drop-in replacement\n",
            "headers: \"longitude\",\"latitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\"households\",\"median_income\",\"median_house_value\"!\n",
            "Read 6 rows.\n",
            "Allocated memory for inputs: 6 rows, 9 columns.\n",
            "Allocated memory for labels: 6 rows, 2 columns.\n",
            "Inputs (first 10):\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "-114.31\t-114.47\t-114.56\t-114.57\t-114.57\t-114.58\t\n",
            "34.19\t34.4\t33.69\t33.64\t33.57\t33.63\t\n",
            "15\t19\t17\t14\t20\t29\t\n",
            "5612\t7650\t720\t1501\t1454\t1387\t\n",
            "1283\t1901\t174\t337\t326\t236\t\n",
            "1015\t1129\t333\t515\t624\t671\t\n",
            "472\t463\t117\t226\t262\t239\t\n",
            "1.4936\t1.82\t1.6509\t3.1917\t1.925\t3.3438\t\n",
            "Labels (first 10):\n",
            "0\t0\t0\t0\t0\t0\t\n",
            "1\t1\t1\t1\t1\t1\t\n",
            "initial accuracy: 0.000000\n",
            "iter: 0, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 1, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 2, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 3, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 4, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 5, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 6, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 7, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 8, logloss: 0.000000, accuracy: 0.000000\n",
            "iter: 9, logloss: 0.000000, accuracy: 0.000000\n",
            "Duration (s): 0.000850\n",
            "final accuracy: 0.000000\n",
            "final weights: \n",
            "[\n",
            "0.205141,\t-0.063689;\n",
            "0.170715,\t0.179966;\n",
            "0.248233,\t-0.182383;\n",
            "-0.099364,\t0.161749;\n",
            "-0.134007,\t0.032545;\n",
            "-0.013630,\t0.077712;\n",
            "-0.081538,\t0.008081;\n",
            "0.272705,\t0.250975;\n",
            "0.081837,\t0.131035\n",
            "]\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44Pk-JL7rAhi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "6WEXHyvpQ-1O"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqs64V1tEysf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736ead32-b8ff-4854-af18-99ea989f6ac8"
      },
      "source": [
        "%%writefile test.cu\n",
        "#include \"fmatrix.cuh\"\n",
        "#include \"classifier_math.cu\"\n",
        "\n",
        "int main() {\n",
        "    // create a random matrix\n",
        "    fmatrix A = fmatrix_create_random_on_device(2,1);\n",
        "    fmatrix B = fmatrix_create_random_on_device(1,2);\n",
        "    fmatrix C = fmatrix_create_random_on_device(1,1);\n",
        "    printf(\"original matrix:\\n\");\n",
        "    fmatrix_device_print(B);\n",
        "    fmatrix_device_print(C);\n",
        "    // add the matrix to itself\n",
        "    fmatrix_tmult(A,1.0,B,C);\n",
        "    // print\n",
        "    printf(\"matrix result:\\n\");\n",
        "    fmatrix_device_print(A);\n",
        "    // free the memory\n",
        "    fmatrix_free_on_device(&A);\n",
        "    fmatrix_free_on_device(&B);\n",
        "    fmatrix_free_on_device(&C);\n",
        "}"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Wno-deprecated-gpu-targets -g -G -I cuda-samples/Common/ -L/usr/local/cuda/include test.cu fmatrix.cu cuda_stuff.cu"
      ],
      "metadata": {
        "id": "KsKCSpp4PoKI",
        "outputId": "87d6d031-4e1f-463b-b2c0-39a835d43d8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/ld: /tmp/tmpxft_00002135_00000000-19_test.o: in function `mat_transp_mul(float, fmatrix, fmatrix, float, fmatrix, int)':\n",
            "/content/classifier_math.cu:65: undefined reference to `cublasCreate_v2'\n",
            "/usr/bin/ld: /content/classifier_math.cu:73: undefined reference to `cublasSgemm_v2'\n",
            "/usr/bin/ld: /content/classifier_math.cu:76: undefined reference to `cublasSgemm_v2'\n",
            "/usr/bin/ld: /content/classifier_math.cu:79: undefined reference to `cublasDestroy_v2'\n",
            "collect2: error: ld returned 1 exit status\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./a.out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vErDd-FXQHdO",
        "outputId": "830d24f6-7093-4ab8-9080-aa0ea20bb518"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: ./a.out: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9uEbwlO9YJjH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}